{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal or command prompt\n",
    "# python3 -m spacy download en\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT &lt;REF&gt; is one of a series of pre-trained n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question &lt;REF&gt; Candidate Paragraph BERT : BERT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecAtt + Doc Reader &lt;REF&gt; 31.4 BERT  50.2 BERT...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specifically, we use SQuAD 1.1 &lt;REF&gt;.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specifically, we use SQuAD 1.1 &lt;REF&gt;.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In recent years, deep pre-training approaches ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In recent years, transfer learning has achieve...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MKDM is implemented from BERT &lt;REF&gt;.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In recent work, &lt;REF&gt; show that pretrained mod...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inspired by the superiority of Transformer &lt;RE...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The autoregressive loss belongs to a large fam...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;REF&gt; study the self-attention of a Transforme...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;REF&gt; study the self-attention of a Transforme...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Recently, several pre-trained transformers suc...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model Architectures of BERT, GPT and ELMo Quot...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paragraph  Index\n",
       "0   BERT <REF> is one of a series of pre-trained n...      0\n",
       "1   Question <REF> Candidate Paragraph BERT : BERT...      1\n",
       "2   DecAtt + Doc Reader <REF> 31.4 BERT  50.2 BERT...      2\n",
       "3               Specifically, we use SQuAD 1.1 <REF>.      3\n",
       "4               Specifically, we use SQuAD 1.1 <REF>.      4\n",
       "5   In recent years, deep pre-training approaches ...      5\n",
       "6   In recent years, transfer learning has achieve...      6\n",
       "7                MKDM is implemented from BERT <REF>.      7\n",
       "8   In recent work, <REF> show that pretrained mod...      8\n",
       "9   Inspired by the superiority of Transformer <RE...      9\n",
       "10  The autoregressive loss belongs to a large fam...     10\n",
       "11  <REF> study the self-attention of a Transforme...     11\n",
       "12  <REF> study the self-attention of a Transforme...     12\n",
       "13  Recently, several pre-trained transformers suc...     13\n",
       "14  Model Architectures of BERT, GPT and ELMo Quot...     14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Bert-629-with-index.csv');\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BERT <REF> is one of a series of pre-trained neural models that can be fine '\n",
      " 'tuned to provide state-of-theart results in NLP including on the SQuAD and '\n",
      " 'NQ tasks that align with our MRC based QA.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-7-bcb88f151c44>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "  data = [re.sub('\\S*@\\S*\\s?<REF>', '', sent) for sent in data]\n",
      "<ipython-input-7-bcb88f151c44>:8: DeprecationWarning: invalid escape sequence \\s\n",
      "  data = [re.sub('\\s+', ' ', sent) for sent in data]\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.paragraph.values.tolist()\n",
    "\n",
    "# Remove Emails and <REF>\n",
    "data = [re.sub('\\S*@\\S*\\s?<REF>', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bert', 'ref', 'is', 'one', 'of', 'series', 'of', 'pre', 'trained', 'neural', 'models', 'that', 'can', 'be', 'fine', 'tuned', 'to', 'provide', 'state', 'of', 'theart', 'results', 'in', 'nlp', 'including', 'on', 'the', 'squad', 'and', 'nq', 'tasks', 'that', 'align', 'with', 'our', 'mrc', 'based', 'qa']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bert ref be series pre train neural model can be fine tune provide state theart result nlp include squad nq task align mrc base', 'question ref candidate paragraph bert bert qa base layer hide dimension attention head paramet transformer network large layer hide dimension attention head paramet transformer network model']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=-1, n_topics=10, perp_tol=0.1,\n",
      "             random_state=100, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_topics=10,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=-1, n_topics=20, perp_tol=0.1,\n",
       "             random_state=100, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7,\n",
    "             learning_method='online', learning_offset=10.0,\n",
    "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
    "             n_components=10, n_jobs=-1, n_topics=20, perp_tol=0.1,\n",
    "             random_state=100, topic_word_prior=None,\n",
    "             total_samples=1000000.0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -53562.51178872012\n",
      "Perplexity:  143.11209282594322\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 10,\n",
      " 'n_jobs': -1,\n",
      " 'n_topics': 10,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_components': [10, 15, 20, 25, 30], 'learning_decay': [0.5, 0.7, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_topics': [10, 15, 20, 25, 30], 'learning_decay': [0.5, 0.7, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(cv=None, error_score='raise',\n",
    "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
    "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
    "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
    "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
    "             n_topics=None, perp_tol=0.1, random_state=None,\n",
    "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
    "       fit_params=None, iid=True, n_jobs=1,\n",
    "       param_grid={'n_topics': [10, 15, 20, 25, 30], 'learning_decay': [0.5, 0.7, 0.9]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -20025.458886164863\n",
      "Model Perplexity:  134.94795798413531\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dominanat topic\n",
    "To classify a document as belonging to a particular topic, a logical approach is to see which topic has the highest contribution to that document and assign it.\n",
    "\n",
    "greened out all major topics in a document and assigned the most dominant topic in its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col6 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col7 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col5 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col6 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col9 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col6 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col6 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col7 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col7 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col6 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col8 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col8 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col9 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col1 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col4 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col7 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col10 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col0 {\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }</style><table id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Topic0</th>        <th class=\"col_heading level0 col1\" >Topic1</th>        <th class=\"col_heading level0 col2\" >Topic2</th>        <th class=\"col_heading level0 col3\" >Topic3</th>        <th class=\"col_heading level0 col4\" >Topic4</th>        <th class=\"col_heading level0 col5\" >Topic5</th>        <th class=\"col_heading level0 col6\" >Topic6</th>        <th class=\"col_heading level0 col7\" >Topic7</th>        <th class=\"col_heading level0 col8\" >Topic8</th>        <th class=\"col_heading level0 col9\" >Topic9</th>        <th class=\"col_heading level0 col10\" >dominant_topic</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col0\" class=\"data row0 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col1\" class=\"data row0 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col2\" class=\"data row0 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col3\" class=\"data row0 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col4\" class=\"data row0 col4\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col5\" class=\"data row0 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col6\" class=\"data row0 col6\" >0.16</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col7\" class=\"data row0 col7\" >0.8</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col8\" class=\"data row0 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col9\" class=\"data row0 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row0_col10\" class=\"data row0 col10\" >7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col0\" class=\"data row1 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col1\" class=\"data row1 col1\" >0.6</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col2\" class=\"data row1 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col3\" class=\"data row1 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col4\" class=\"data row1 col4\" >0.24</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col5\" class=\"data row1 col5\" >0.12</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col6\" class=\"data row1 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col7\" class=\"data row1 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col8\" class=\"data row1 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col9\" class=\"data row1 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row1_col10\" class=\"data row1 col10\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col0\" class=\"data row2 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col1\" class=\"data row2 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col2\" class=\"data row2 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col3\" class=\"data row2 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col4\" class=\"data row2 col4\" >0.23</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col5\" class=\"data row2 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col6\" class=\"data row2 col6\" >0.31</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col7\" class=\"data row2 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col8\" class=\"data row2 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col9\" class=\"data row2 col9\" >0.36</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row2_col10\" class=\"data row2 col10\" >9</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col0\" class=\"data row3 col0\" >0.55</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col1\" class=\"data row3 col1\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col2\" class=\"data row3 col2\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col3\" class=\"data row3 col3\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col4\" class=\"data row3 col4\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col5\" class=\"data row3 col5\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col6\" class=\"data row3 col6\" >0.29</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col7\" class=\"data row3 col7\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col8\" class=\"data row3 col8\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col9\" class=\"data row3 col9\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row3_col10\" class=\"data row3 col10\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col0\" class=\"data row4 col0\" >0.55</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col1\" class=\"data row4 col1\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col2\" class=\"data row4 col2\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col3\" class=\"data row4 col3\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col4\" class=\"data row4 col4\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col5\" class=\"data row4 col5\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col6\" class=\"data row4 col6\" >0.29</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col7\" class=\"data row4 col7\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col8\" class=\"data row4 col8\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col9\" class=\"data row4 col9\" >0.02</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col0\" class=\"data row5 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col1\" class=\"data row5 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col2\" class=\"data row5 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col3\" class=\"data row5 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col4\" class=\"data row5 col4\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col5\" class=\"data row5 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col6\" class=\"data row5 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col7\" class=\"data row5 col7\" >0.91</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col8\" class=\"data row5 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col9\" class=\"data row5 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row5_col10\" class=\"data row5 col10\" >7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col0\" class=\"data row6 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col1\" class=\"data row6 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col2\" class=\"data row6 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col3\" class=\"data row6 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col4\" class=\"data row6 col4\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col5\" class=\"data row6 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col6\" class=\"data row6 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col7\" class=\"data row6 col7\" >0.91</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col8\" class=\"data row6 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col9\" class=\"data row6 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row6_col10\" class=\"data row6 col10\" >7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col0\" class=\"data row7 col0\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col1\" class=\"data row7 col1\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col2\" class=\"data row7 col2\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col3\" class=\"data row7 col3\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col4\" class=\"data row7 col4\" >0.7</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col5\" class=\"data row7 col5\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col6\" class=\"data row7 col6\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col7\" class=\"data row7 col7\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col8\" class=\"data row7 col8\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col9\" class=\"data row7 col9\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row7_col10\" class=\"data row7 col10\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col0\" class=\"data row8 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col1\" class=\"data row8 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col2\" class=\"data row8 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col3\" class=\"data row8 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col4\" class=\"data row8 col4\" >0.45</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col5\" class=\"data row8 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col6\" class=\"data row8 col6\" >0.24</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col7\" class=\"data row8 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col8\" class=\"data row8 col8\" >0.25</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col9\" class=\"data row8 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row8_col10\" class=\"data row8 col10\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col0\" class=\"data row9 col0\" >0.22</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col1\" class=\"data row9 col1\" >0.18</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col2\" class=\"data row9 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col3\" class=\"data row9 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col4\" class=\"data row9 col4\" >0.27</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col5\" class=\"data row9 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col6\" class=\"data row9 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col7\" class=\"data row9 col7\" >0.08</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col8\" class=\"data row9 col8\" >0.21</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col9\" class=\"data row9 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row9_col10\" class=\"data row9 col10\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col0\" class=\"data row10 col0\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col1\" class=\"data row10 col1\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col2\" class=\"data row10 col2\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col3\" class=\"data row10 col3\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col4\" class=\"data row10 col4\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col5\" class=\"data row10 col5\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col6\" class=\"data row10 col6\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col7\" class=\"data row10 col7\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col8\" class=\"data row10 col8\" >0.03</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col9\" class=\"data row10 col9\" >0.7</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row10_col10\" class=\"data row10 col10\" >9</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col0\" class=\"data row11 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col1\" class=\"data row11 col1\" >0.39</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col2\" class=\"data row11 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col3\" class=\"data row11 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col4\" class=\"data row11 col4\" >0.53</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col5\" class=\"data row11 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col6\" class=\"data row11 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col7\" class=\"data row11 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col8\" class=\"data row11 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col9\" class=\"data row11 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row11_col10\" class=\"data row11 col10\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col0\" class=\"data row12 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col1\" class=\"data row12 col1\" >0.39</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col2\" class=\"data row12 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col3\" class=\"data row12 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col4\" class=\"data row12 col4\" >0.53</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col5\" class=\"data row12 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col6\" class=\"data row12 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col7\" class=\"data row12 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col8\" class=\"data row12 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col9\" class=\"data row12 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row12_col10\" class=\"data row12 col10\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col0\" class=\"data row13 col0\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col1\" class=\"data row13 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col2\" class=\"data row13 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col3\" class=\"data row13 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col4\" class=\"data row13 col4\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col5\" class=\"data row13 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col6\" class=\"data row13 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col7\" class=\"data row13 col7\" >0.89</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col8\" class=\"data row13 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col9\" class=\"data row13 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row13_col10\" class=\"data row13 col10\" >7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col0\" class=\"data row14 col0\" >0.95</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col1\" class=\"data row14 col1\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col2\" class=\"data row14 col2\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col3\" class=\"data row14 col3\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col4\" class=\"data row14 col4\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col5\" class=\"data row14 col5\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col6\" class=\"data row14 col6\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col7\" class=\"data row14 col7\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col8\" class=\"data row14 col8\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col9\" class=\"data row14 col9\" >0.01</td>\n",
       "                        <td id=\"T_c65084a8_d24e_11e9_abf5_d0a637edfd15row14_col10\" class=\"data row14 col10\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11db36208>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(lda_model.n_topics)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Num</th>\n",
       "      <th>Num Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Num  Num Documents\n",
       "0          7            231\n",
       "1          4            209\n",
       "2          5            130\n",
       "3          0            128\n",
       "4          2             72\n",
       "5          1             57\n",
       "6          9             50\n",
       "7          6             48\n",
       "8          3             39\n",
       "9          8             37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review topics distribution across documents\n",
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2471947929584324651178188\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2471947929584324651178188_data = {\"mdsDat\": {\"x\": [-169.9400634765625, -50.139137268066406, -45.7049560546875, 156.79393005371094, -159.486572265625, -65.48941040039062, 167.2571563720703, 43.01333236694336, 47.45911407470703, 62.816349029541016], \"y\": [-99.3420639038086, -26.852157592773438, 113.09027099609375, -147.89205932617188, 37.08674240112305, -165.08139038085938, -11.461771011352539, -223.89492797851562, -83.93579864501953, 54.3021240234375], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [14.948700517736057, 13.507425244353715, 13.425669806708058, 10.637171222306664, 10.123687903571788, 9.364552021641993, 8.665378212187143, 7.658153574416778, 6.026357880797359, 5.642903616280454]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [214.0, 328.0, 81.0, 80.0, 183.0, 115.0, 80.0, 311.0, 93.0, 447.0, 78.0, 214.0, 557.0, 58.0, 131.0, 75.0, 121.0, 73.0, 123.0, 61.0, 110.0, 76.0, 84.0, 77.0, 56.0, 54.0, 84.0, 90.0, 969.0, 65.0, 26.326558436348922, 15.640417837172427, 27.00592377040208, 13.40558545688187, 24.15437449523658, 14.79015131873669, 9.519768038071458, 58.31866452856477, 7.868759020890094, 9.515193813029494, 20.885177722319355, 10.476242703173343, 6.293666054664057, 64.84558546957071, 7.859313851381205, 9.811756296553407, 9.535443277153888, 86.56249372068675, 35.69231497801129, 79.44222903578509, 10.170923597840739, 4.25993613429296, 63.99263361095746, 6.704814189483341, 4.877484735624621, 121.04521204293589, 5.282884244820887, 72.34542095186333, 6.5340202495988535, 4.222613354120794, 129.63297722386443, 100.69918569553113, 132.7851840967213, 54.28023466825459, 14.278456990197682, 32.90666212494853, 19.907156282612256, 13.39384357138548, 14.736300749094614, 15.691007555865705, 12.826014018453467, 12.390321379211924, 11.556476938699975, 10.691804628992166, 39.693706969283866, 23.6653874909506, 205.82813063182363, 108.81817124878943, 12.35119743846003, 16.9648865319275, 32.00399919394417, 26.79701524143312, 36.813123083141726, 10.05104265988655, 19.850019586899297, 8.57979909191003, 8.479307014753786, 9.47459870414537, 9.767338922788085, 12.070476184609069, 6.664977102681314, 29.688404353337546, 15.677198006720959, 25.73921836951877, 4.85659330920103, 6.694229428060883, 9.109928053507094, 11.964948828333696, 8.666089110054562, 5.504079822550009, 5.7923235640752075, 4.572604857598096, 16.616677056657956, 17.12176446263542, 40.787018405919305, 59.85798984401066, 65.06327944596667, 130.19080934590738, 10.96899471591432, 54.10222298969772, 27.97867337920811, 25.54305824601168, 39.420363115795546, 15.737528015789069, 14.511563677866043, 14.381046778759478, 10.558419474001647, 91.99546649078358, 27.261255933716434, 19.500058790714604, 16.589562720493294, 22.045166225275956, 49.82007513821966, 14.527350000043363, 11.44345488498584, 12.787967210263918, 12.636946410727766, 9.207370749884666, 20.876773925962286, 8.828371819072286, 11.323707825535486, 9.57079216210689, 15.946613649005185, 9.603264934223215, 10.540350950051007, 6.784223364392127, 20.032379468537464, 11.499008243882978, 13.27311368300412, 7.346138762903681, 5.582792208388824, 24.414167830686377, 5.854087088819449, 34.57968558767363, 30.776385243068884, 125.24351215514861, 22.32664997953568, 111.4345380054419, 32.576806275232656, 25.813032721316006, 41.16869962131614, 23.284229258660876, 102.19536255007112, 16.858773220536175, 39.825103048503976, 13.358368415332421, 18.919278963511363, 15.169248777157376, 15.333920379452152, 14.274261150753501, 12.896550750987055, 9.990434274548022, 44.70595292444545, 11.969320975433128, 12.473342364717515, 52.3179942136668, 28.80132034858278, 15.525495734381085, 8.012545897599667, 7.023253489294349, 13.85213142069551, 7.268306585722094, 7.16389742629301, 7.810272380221836, 4.994414039619658, 7.69467371468586, 9.954663376321015, 34.56060897212216, 10.107241392831153, 4.420410620425982, 5.044835718779719, 29.00103207701128, 4.814337478917132, 5.669414095471281, 4.589527226181428, 4.48690596373632, 3.764600429999301, 4.141390458073823, 11.201135039865832, 5.112398366967534, 4.253455891228837, 134.62422385097298, 21.783304205196618, 73.16135678302847, 51.92317922550195, 74.65742324469686, 14.42675406843208, 35.27828542416395, 90.15061118628134, 20.364869774439274, 11.223933215874975, 12.160152185504655, 18.789258863786355, 11.961882130571377, 13.671027813984635, 12.81267355216331, 8.917232505111096, 25.211074213741853, 19.006657697967615, 11.658423524067704, 11.687915231819105, 20.571533232141753, 10.702811316162746, 11.292677528128268, 11.438602869997942, 14.559861938026105, 8.573229870653561, 6.509766256577789, 10.72190886216016, 31.63756499374061, 32.80631836276741, 15.607168625692752, 8.922143136167435, 5.892129427837062, 31.02216925287182, 8.856900702710032, 33.0586899974992, 8.317645587083616, 10.396175674397933, 11.595839279652221, 4.6765695067579784, 8.291078246138683, 7.133836283800486, 4.336626149146125, 40.018842531327074, 3.960352155096141, 9.410506685600645, 23.678374375248165, 20.359087409127934, 117.44315512705109, 22.88042083791683, 17.430660128636983, 123.15371485070132, 52.91112021743162, 13.374965762241281, 12.203310779482349, 20.565637808376767, 14.073919943173387, 12.417048148876113, 13.886720145226121, 12.457471637828297, 10.37255943131613, 11.917118118907378, 16.65649826697929, 19.381006672639383, 17.366631816364972, 34.90289025808775, 12.86149063785256, 10.600859417903225, 44.144886820583324, 18.146155940990102, 11.523119458096463, 6.9712607270466105, 6.992671679912258, 12.902069090721753, 5.428075083547283, 6.347940519166772, 17.663892723947008, 39.99252908626305, 10.551745781450697, 6.945642029448188, 6.613999069325763, 9.403767741349741, 4.718223309189643, 36.30059974046675, 33.27456732537042, 6.284835519120907, 4.729241541167247, 18.555823758732224, 7.575949884816516, 18.07555480024468, 14.447187772129617, 78.62626133606328, 34.96963329683133, 20.149766709771512, 14.024099641102215, 39.37413733736195, 20.543618208091743, 20.607083611729287, 13.306906256337811, 12.497393317746166, 79.91305915604798, 11.77763487542124, 10.804297009100331, 10.803486208026435, 70.1486099892641, 17.55029709797497, 24.956122777398402, 13.82329254984451, 18.38571276966617, 9.625834136807347, 26.768450990477483, 9.756108387521078, 11.775052178941065, 35.2123596715484, 6.264999846449651, 7.115254608731725, 78.33490347074564, 12.1309873446999, 48.657831219947425, 4.481863530347822, 8.230793882671723, 4.8364093272292354, 3.0083549821136675, 5.510835556731499, 25.373800898963367, 16.268020263086097, 9.124362808827035, 2.043951260308251, 11.853727222601846, 4.538617406512143, 7.937973209570785, 56.29932129646895, 96.35026797795265, 58.86885078982453, 33.932488367032605, 9.236549311317203, 13.892585814172405, 13.892576679727675, 21.100517633933446, 47.407647430793034, 10.705182860476155, 10.60275358891096, 13.574315902205315, 8.960072435524513, 9.329961729269902, 8.350672938328653, 6.9938635195661805, 28.58617587472765, 10.1467565711441, 9.842227340768867, 22.698669618835357, 8.06380075406693, 5.285339721514768, 6.01018607808635, 10.244818888199339, 10.495288013814436, 11.290617019180154, 8.84506164936032, 8.160055083269706, 9.578172963546992, 9.041938297756534, 4.848159799400716, 8.897609369835205, 16.59156688677393, 6.414305823201327, 4.6982378492613215, 16.375797980388175, 18.71680983639437, 15.949410311313015, 29.215511045149054, 112.39885853424005, 21.101910349124232, 23.094548566209127, 24.901480987092743, 18.476475678257533, 28.381106051224766, 20.600025666603404, 9.714048543895785, 15.750847828911343, 24.721629627441082, 10.010438063092288, 15.685093126077179, 11.045537950513381, 8.990177742681103, 8.171173688685645, 12.70040593244744, 11.836313775332535, 12.613979274423368, 25.344449000999212, 23.301803686428276, 32.31991114785978, 7.7018310615501475, 5.617030699019823, 6.40076877620416, 6.217492746998314, 12.349033439494152, 32.187739544207844, 4.276771369599473, 6.359188478775918, 9.512608201251197, 5.930921425323273, 8.715050327248237, 4.867081086953552, 30.214291176117804, 3.513387885231218, 3.400902123395842, 4.397796812939529, 2.5162825649739013, 23.43441698892917, 58.472042107683684, 32.4334671072853, 57.39734980645843, 7.450637465476521, 8.223126611684798, 8.233468887759894, 8.410754031479383, 7.088928487154531, 16.47685015349084, 16.47682366777978, 13.406620146494598, 12.37375792370247, 75.54343604072498, 67.29536837693995, 11.290123521834962, 8.289599302575533, 11.085356073099273, 7.490541477371462, 13.338246290084927, 23.660327170449754, 5.058295343956561, 27.4109141257781, 4.676420022969013, 16.51134994237429, 16.913661685437432, 6.629112817129035, 5.407129717917309, 6.476305785358218, 11.11648599096499, 2.7923536440591947, 2.1492379167305353, 4.972974028283502, 3.388167900391408, 7.31117856819881, 4.964445399594046, 4.246190037314617, 11.631643507135466, 2.571942777905844, 7.158580677499082, 34.248020197831146, 46.40031843815302, 7.298625857991359, 6.586291106347553, 9.463790985882019, 6.849888709745669, 5.87413304874803, 5.294308890814657], \"Term\": [\"word\", \"language\", \"network\", \"neural\", \"transformer\", \"embedding\", \"layer\", \"task\", \"natural\", \"bert\", \"attention\", \"representation\", \"model\", \"token\", \"base\", \"recent\", \"sentence\", \"elmo\", \"nlp\", \"question\", \"encoder\", \"recently\", \"learn\", \"bidirectional\", \"pretraine\", \"processing\", \"art\", \"state\", \"ref\", \"architecture\", \"masked\", \"target\", \"objective\", \"supervise\", \"tuning\", \"wikipedia\", \"universal\", \"bidirectional\", \"design\", \"develop\", \"unsupervised\", \"general\", \"purpose\", \"encoder\", \"previous\", \"consider\", \"corpus\", \"train\", \"fine\", \"transformer\", \"specific\", \"particular\", \"pre\", \"mask\", \"benefit\", \"language\", \"finetune\", \"representation\", \"pretrained\", \"trained\", \"model\", \"bert\", \"ref\", \"task\", \"tune\", \"use\", \"base\", \"learning\", \"learn\", \"sentence\", \"training\", \"large\", \"approach\", \"pretraine\", \"vector\", \"vec\", \"word\", \"embedding\", \"represent\", \"glove\", \"contextual\", \"contextualized\", \"embed\", \"position\", \"level\", \"linguistic\", \"contextualize\", \"employ\", \"length\", \"encode\", \"form\", \"context\", \"similar\", \"input\", \"investigate\", \"popular\", \"extract\", \"information\", \"document\", \"leverage\", \"trained\", \"compute\", \"feature\", \"different\", \"sentence\", \"representation\", \"use\", \"ref\", \"unsupervised\", \"bert\", \"train\", \"pre\", \"model\", \"elmo\", \"text\", \"encoder\", \"method\", \"natural\", \"understanding\", \"inference\", \"nli\", \"variety\", \"processing\", \"benchmark\", \"lead\", \"wide\", \"sentiment\", \"glue\", \"range\", \"report\", \"significant\", \"effective\", \"improvement\", \"analysis\", \"recognition\", \"evaluation\", \"improve\", \"success\", \"new\", \"textual\", \"entailment\", \"include\", \"progress\", \"art\", \"recently\", \"language\", \"achieve\", \"task\", \"state\", \"performance\", \"nlp\", \"result\", \"ref\", \"question\", \"model\", \"propose\", \"bert\", \"pre\", \"use\", \"representation\", \"train\", \"addition\", \"pretraine\", \"scale\", \"corpora\", \"elmo\", \"gpt\", \"advance\", \"framework\", \"detection\", \"modeling\", \"leverage\", \"openai\", \"inspire\", \"investigate\", \"field\", \"build\", \"large\", \"make\", \"available\", \"step\", \"recent\", \"benefit\", \"explore\", \"cross\", \"mention\", \"version\", \"computer\", \"transfer\", \"vision\", \"technique\", \"model\", \"learn\", \"language\", \"use\", \"bert\", \"deep\", \"representation\", \"ref\", \"nlp\", \"work\", \"performance\", \"train\", \"training\", \"pre\", \"task\", \"feature\", \"good\", \"knowledge\", \"way\", \"module\", \"baseline\", \"test\", \"development\", \"section\", \"compare\", \"small\", \"adopt\", \"dnn\", \"tune\", \"method\", \"set\", \"study\", \"accuracy\", \"approach\", \"pretrained\", \"fine\", \"year\", \"improvement\", \"experiment\", \"progress\", \"perform\", \"corpus\", \"size\", \"base\", \"report\", \"introduce\", \"large\", \"performance\", \"bert\", \"training\", \"result\", \"ref\", \"model\", \"achieve\", \"dataset\", \"use\", \"state\", \"art\", \"block\", \"pair\", \"release\", \"passage\", \"span\", \"comprehension\", \"read\", \"answer\", \"extraction\", \"current\", \"question\", \"translation\", \"generate\", \"ner\", \"labeling\", \"relation\", \"available\", \"entailment\", \"machine\", \"text\", \"multiple\", \"explore\", \"generation\", \"squad\", \"structure\", \"state\", \"art\", \"textual\", \"mrc\", \"sequence\", \"single\", \"dataset\", \"achieve\", \"ref\", \"task\", \"nlp\", \"result\", \"model\", \"use\", \"bert\", \"train\", \"transformer\", \"layer\", \"hidden\", \"unit\", \"rnn\", \"attention\", \"head\", \"multi\", \"lstm\", \"mechanism\", \"standard\", \"self\", \"decoder\", \"parameter\", \"architecture\", \"cross\", \"combine\", \"transformer\", \"apply\", \"base\", \"original\", \"relation\", \"finetune\", \"second\", \"consider\", \"encoder\", \"bidirectional\", \"follow\", \"adopt\", \"propose\", \"paper\", \"embed\", \"bert\", \"ref\", \"model\", \"use\", \"large\", \"score\", \"source\", \"predict\", \"token\", \"cls\", \"replace\", \"instance\", \"setting\", \"refer\", \"candidate\", \"second\", \"datum\", \"mask\", \"prediction\", \"follow\", \"end\", \"order\", \"compute\", \"number\", \"squad\", \"example\", \"single\", \"classifier\", \"obtain\", \"multiple\", \"evaluate\", \"paper\", \"input\", \"specifically\", \"size\", \"classification\", \"dataset\", \"sequence\", \"sentence\", \"ref\", \"training\", \"train\", \"task\", \"pre\", \"model\", \"use\", \"set\", \"research\", \"transfer\", \"demonstrate\", \"downstream\", \"year\", \"vision\", \"application\", \"specific\", \"success\", \"semantic\", \"learning\", \"work\", \"recent\", \"focus\", \"computer\", \"technique\", \"label\", \"apply\", \"learn\", \"detection\", \"parameter\", \"information\", \"dnn\", \"range\", \"prediction\", \"nlp\", \"convolutional\", \"effective\", \"image\", \"benefit\", \"sentence\", \"task\", \"representation\", \"ref\", \"classification\", \"training\", \"word\", \"use\", \"pre\", \"cnn\", \"problem\", \"recurrent\", \"dependency\", \"network\", \"neural\", \"long\", \"variant\", \"convolutional\", \"mrc\", \"introduce\", \"propose\", \"english\", \"recently\", \"end\", \"include\", \"deep\", \"various\", \"image\", \"capture\", \"sequence\", \"computer\", \"form\", \"example\", \"field\", \"machine\", \"modeling\", \"mechanism\", \"architecture\", \"vision\", \"achieve\", \"model\", \"ref\", \"attention\", \"performance\", \"task\", \"language\", \"transformer\", \"text\"], \"Total\": [214.0, 328.0, 81.0, 80.0, 183.0, 115.0, 80.0, 311.0, 93.0, 447.0, 78.0, 214.0, 557.0, 58.0, 131.0, 75.0, 121.0, 73.0, 123.0, 61.0, 110.0, 76.0, 84.0, 77.0, 56.0, 54.0, 84.0, 90.0, 969.0, 65.0, 27.214408970042747, 16.52834052855943, 30.15967001431141, 15.555179284162818, 28.168015219429158, 17.549238813056437, 12.677867473126925, 77.72194447192689, 10.688544254878137, 13.641221492319655, 32.71303206963881, 17.46239288744901, 10.6324705691964, 110.36655747195002, 13.607409715654496, 21.4333022151441, 21.30237279621141, 193.58760235635486, 80.81624594496469, 183.23791895013218, 25.16816308988507, 10.714009603701317, 163.45989876366914, 17.640873238570705, 12.892728708058947, 328.82123629944175, 14.601635147141648, 214.75295707002923, 21.354009599962154, 15.432222336414378, 557.3902326599738, 447.31646481667383, 969.64873812255, 311.3820922360797, 57.48020322223872, 270.1413339429393, 131.9077640783531, 59.12473072244457, 84.02032994106634, 121.38687666370917, 85.45495570882665, 83.12514564240756, 66.67414414345694, 56.18671683343898, 40.5844531406015, 24.55608806477994, 214.849316960369, 115.33273625702608, 13.241952415325239, 18.930688661146196, 38.10209998866254, 32.232728360597584, 45.544507949558316, 14.301591099073649, 28.64535674969803, 12.426456082050965, 12.383943820474977, 14.410475038281312, 15.326920230777308, 19.11978651290295, 10.617885893317393, 49.03060900236114, 25.983415590700204, 47.279245849707664, 10.642826334577984, 15.392197098811737, 21.238856891511084, 29.433087226997632, 21.334886307424842, 14.60249973974058, 15.432222336414378, 12.606988154493525, 46.403553519248845, 49.47982767332411, 121.38687666370917, 214.75295707002923, 270.1413339429393, 969.64873812255, 32.71303206963881, 447.31646481667383, 193.58760235635486, 163.45989876366914, 557.3902326599738, 73.3286946062387, 84.29001631971492, 110.36655747195002, 61.680916396648755, 93.16412121138771, 28.14925537835982, 20.388029600740694, 17.477571016248678, 23.288208084675293, 54.54294895609527, 18.49376184286349, 15.585935645892533, 18.47184292866108, 18.309163686086688, 13.581761699078628, 31.681480744664096, 13.580117719999123, 17.48454969018715, 15.770539957255838, 27.134212158097753, 17.46343427247146, 20.5659808609636, 13.465219826950907, 40.01366347459318, 24.11902539516441, 30.12208825068242, 16.70542967185702, 12.720268256092009, 56.35602528850205, 13.623728478553929, 84.9370878190809, 76.1205520181918, 328.82123629944175, 59.85153736279665, 311.3820922360797, 90.83797424184267, 71.54110043829168, 123.95430780348279, 65.52506940091502, 969.64873812255, 61.79318748722391, 557.3902326599738, 65.17895676398466, 447.31646481667383, 163.45989876366914, 270.1413339429393, 214.75295707002923, 193.58760235635486, 10.876947484631541, 56.18671683343898, 15.81001692515655, 16.747583850544963, 73.3286946062387, 41.23319500032647, 23.7045977227678, 12.758305055295624, 12.081801927542477, 25.765149753186954, 14.60249973974058, 14.660448977476568, 16.551060473671125, 10.642826334577984, 16.812034471248325, 22.382478649305057, 83.12514564240756, 24.327680153693773, 10.843408815165006, 12.771104128867425, 75.61727634874879, 12.892728708058947, 15.680939066804388, 12.733862955690944, 13.587862195759055, 11.753076605695002, 13.230184427110466, 36.878509137491896, 17.35394213530889, 15.115471924656761, 557.3902326599738, 84.02032994106634, 328.82123629944175, 270.1413339429393, 447.31646481667383, 58.548670705365865, 214.75295707002923, 969.64873812255, 123.95430780348279, 54.38099704441605, 71.54110043829168, 193.58760235635486, 85.45495570882665, 163.45989876366914, 311.3820922360797, 46.403553519248845, 26.099488386368506, 20.30713814185876, 12.576509841670328, 14.46197977725605, 27.177726651613103, 14.571262512689456, 16.54259981705456, 17.440544949576626, 22.45446442354119, 13.754565428882838, 10.666749183739926, 18.884241116770237, 57.48020322223872, 61.680916396648755, 32.20110284667067, 18.46733623229474, 12.65847689638745, 66.67414414345694, 21.354009599962154, 80.81624594496469, 21.13215661034098, 27.134212158097753, 30.869560226524218, 13.623728478553929, 24.347388547407956, 21.30237279621141, 13.680066625615618, 131.9077640783531, 13.580117719999123, 32.59551983776343, 83.12514564240756, 71.54110043829168, 447.31646481667383, 85.45495570882665, 65.52506940091502, 969.64873812255, 557.3902326599738, 59.85153736279665, 58.72619235671649, 270.1413339429393, 90.83797424184267, 84.9370878190809, 14.773318093103635, 14.773915772526284, 12.780583255544386, 14.750280412394362, 20.645891153791634, 24.557016975635623, 22.58658495558636, 47.10267364021195, 17.745335347145534, 14.633068523799135, 61.79318748722391, 25.508603893112156, 18.443810981694615, 11.695809222547995, 11.820318078123535, 24.462244528213212, 10.843408815165006, 12.720268256092009, 36.548308790365674, 84.29001631971492, 23.501879969976972, 15.680939066804388, 15.720260518113907, 22.633683573618004, 11.751687806713715, 90.83797424184267, 84.9370878190809, 16.70542967185702, 13.082028074694021, 51.4208834793345, 21.550810927746976, 58.72619235671649, 59.85153736279665, 969.64873812255, 311.3820922360797, 123.95430780348279, 65.52506940091502, 557.3902326599738, 270.1413339429393, 447.31646481667383, 193.58760235635486, 183.23791895013218, 80.80074324588043, 12.66532355253229, 11.691961374879137, 11.69197847653734, 78.23256187601574, 20.43687361209131, 29.201277033515872, 17.546211950984773, 23.57443853484625, 12.690788279098767, 37.94759854127603, 14.581665253991961, 18.923674364082746, 65.93786498883011, 12.733862955690944, 16.60549170423934, 183.23791895013218, 32.058659097896765, 131.9077640783531, 12.716751584268868, 24.462244528213212, 14.601635147141648, 10.80175812883449, 21.4333022151441, 110.36655747195002, 77.72194447192689, 44.13127261743903, 10.666749183739926, 65.17895676398466, 25.25888766256698, 45.544507949558316, 447.31646481667383, 969.64873812255, 557.3902326599738, 270.1413339429393, 83.12514564240756, 14.779081214661018, 14.779081761331327, 22.63237800069173, 58.842319130853355, 13.754708169594384, 13.694501552665033, 17.85435121612986, 12.766482441157189, 13.723529675866162, 12.796185134441062, 10.80175812883449, 45.09421768122811, 17.640873238570705, 17.89091189220819, 44.13127261743903, 15.899583345278149, 10.735988695292148, 12.606988154493525, 21.661391011560863, 22.633683573618004, 24.600350281704998, 21.550810927746976, 20.38781703223569, 24.453451994808344, 23.501879969976972, 13.568568529998313, 25.25888766256698, 47.279245849707664, 18.652594681599663, 13.680066625615618, 49.40679209021707, 58.72619235671649, 51.4208834793345, 121.38687666370917, 969.64873812255, 85.45495570882665, 193.58760235635486, 311.3820922360797, 163.45989876366914, 557.3902326599738, 270.1413339429393, 32.20110284667067, 16.63158339393574, 36.878509137491896, 16.284943921587217, 27.363366876115467, 21.13215661034098, 17.35394213530889, 16.178604000587875, 25.16816308988507, 24.11902539516441, 26.058557063910694, 59.12473072244457, 54.38099704441605, 75.61727634874879, 18.07115927354756, 13.230184427110466, 15.115471924656761, 15.129596966234734, 32.058659097896765, 84.02032994106634, 12.081801927542477, 18.923674364082746, 29.433087226997632, 18.884241116770237, 31.681480744664096, 17.89091189220819, 123.95430780348279, 15.377075283815254, 15.770539957255838, 21.097188111158758, 12.892728708058947, 121.38687666370917, 311.3820922360797, 214.75295707002923, 969.64873812255, 49.40679209021707, 85.45495570882665, 214.849316960369, 270.1413339429393, 163.45989876366914, 17.35951326094872, 17.359512779881143, 14.289285189439545, 13.265132478373744, 81.8616529554644, 80.10510442496815, 14.271802863627073, 11.112546786556223, 15.377075283815254, 13.082028074694021, 32.59551983776343, 65.17895676398466, 13.939409185120681, 76.1205520181918, 15.899583345278149, 56.35602528850205, 58.548670705365865, 25.714992054137415, 21.097188111158758, 26.59897146594445, 51.4208834793345, 13.230184427110466, 10.617885893317393, 24.600350281704998, 16.812034471248325, 36.548308790365674, 25.765149753186954, 23.57443853484625, 65.93786498883011, 17.35394213530889, 59.85153736279665, 557.3902326599738, 969.64873812255, 78.23256187601574, 71.54110043829168, 311.3820922360797, 328.82123629944175, 183.23791895013218, 84.29001631971492], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8674, 1.8453, 1.7901, 1.7518, 1.7468, 1.7295, 1.6141, 1.6133, 1.5943, 1.5403, 1.4518, 1.3896, 1.3762, 1.3687, 1.3516, 1.1192, 1.0967, 1.0957, 1.0833, 1.0648, 0.9945, 0.9782, 0.9627, 0.9332, 0.9285, 0.9012, 0.8839, 0.8125, 0.7163, 0.6045, 0.442, 0.4094, -0.0877, 0.1537, 0.5079, -0.2047, 0.0095, 0.4157, 0.1598, -0.1453, 0.004, -0.0029, 0.148, 0.2413, 1.9797, 1.965, 1.959, 1.9438, 1.9323, 1.8923, 1.8275, 1.8172, 1.7891, 1.6492, 1.6351, 1.6315, 1.6232, 1.5826, 1.5514, 1.542, 1.5363, 1.5002, 1.4967, 1.3939, 1.2174, 1.1693, 1.1555, 1.1018, 1.101, 1.0262, 1.022, 0.9878, 0.975, 0.9407, 0.9113, 0.7244, 0.5783, -0.006, 0.9092, -0.1105, 0.0676, 0.1457, -0.6471, 0.463, 0.2426, -0.036, 0.2369, 1.9954, 1.9759, 1.9635, 1.9559, 1.9531, 1.9174, 1.7666, 1.6991, 1.6403, 1.6372, 1.6193, 1.5909, 1.5774, 1.5736, 1.5086, 1.4765, 1.41, 1.3396, 1.3225, 1.3161, 1.2673, 1.1885, 1.1864, 1.1845, 1.1715, 1.1633, 1.1094, 1.1024, 1.0427, 1.0219, 0.9804, 0.9825, 0.9886, 0.9058, 0.9733, -0.242, 0.7091, -0.6308, 0.423, -1.1551, -0.3693, -0.8609, -0.703, -0.7008, 2.1558, 2.0122, 1.9625, 1.9462, 1.9032, 1.882, 1.8176, 1.7756, 1.6983, 1.6202, 1.5431, 1.5247, 1.4898, 1.4842, 1.4592, 1.4306, 1.3632, 1.3625, 1.3435, 1.312, 1.2825, 1.2558, 1.2235, 1.2203, 1.1328, 1.1023, 1.0793, 1.0492, 1.0187, 0.9728, 0.82, 0.8909, 0.738, 0.5916, 0.4505, 0.84, 0.4346, -0.1346, 0.4347, 0.6628, 0.4687, -0.0916, 0.2746, -0.2405, -0.9498, 0.5914, 2.2557, 2.2241, 2.2145, 2.0773, 2.0118, 1.9817, 1.9085, 1.8685, 1.8571, 1.8176, 1.7965, 1.7243, 1.6932, 1.6589, 1.566, 1.5628, 1.5256, 1.5252, 1.4102, 1.3964, 1.3579, 1.3309, 1.3112, 1.221, 1.213, 1.1963, 1.1414, 1.0975, 1.058, 1.0479, 1.0345, 1.0335, 0.953, 0.9726, 0.9661, 0.2268, -0.0644, 0.7918, 0.7191, -0.285, 0.4255, 0.3675, 2.3063, 2.1977, 2.1595, 2.155, 2.1535, 2.1315, 2.1054, 2.0685, 2.0464, 2.0459, 2.0319, 2.0277, 1.8979, 1.8508, 1.8433, 1.7285, 1.6763, 1.6732, 1.6411, 1.6227, 1.5674, 1.5539, 1.5025, 1.4899, 1.4557, 1.451, 1.4311, 1.3906, 1.3508, 1.349, 1.3228, 1.1899, 0.9469, -0.144, 0.1817, 0.5515, 0.8266, -0.2819, -0.2082, -0.7094, -0.3092, -0.317, 2.4348, 2.3732, 2.3669, 2.3668, 2.3368, 2.2936, 2.2887, 2.2074, 2.1972, 2.1694, 2.0969, 2.044, 1.9714, 1.8185, 1.7365, 1.5983, 1.596, 1.474, 1.4485, 1.403, 1.3566, 1.3409, 1.1675, 1.0876, 0.9757, 0.8819, 0.8696, 0.7936, 0.7413, 0.7293, 0.6988, 0.3733, 0.1369, 0.1979, 0.3713, 0.2487, 2.5075, 2.5075, 2.4993, 2.3533, 2.3187, 2.3135, 2.2953, 2.2154, 2.1835, 2.1426, 2.1347, 2.1136, 2.0163, 1.9718, 1.9045, 1.8905, 1.8607, 1.8286, 1.8206, 1.8009, 1.7906, 1.6788, 1.6537, 1.6321, 1.6142, 1.5402, 1.526, 1.5222, 1.5019, 1.5006, 1.4651, 1.4259, 1.3988, 1.1451, 0.4145, 1.1708, 0.4433, 0.0433, 0.3893, -0.4081, -0.0043, 1.371, 2.7546, 2.4091, 2.3224, 2.2525, 2.1603, 2.1513, 2.126, 2.1251, 2.0972, 2.0835, 1.9619, 1.9615, 1.959, 1.9562, 1.9523, 1.9497, 1.9197, 1.855, 1.8496, 1.7705, 1.7185, 1.6795, 1.6509, 1.5183, 1.5072, 1.3974, 1.3327, 1.2749, 1.241, 1.1751, 1.1643, 1.1366, 0.9187, -0.0179, 0.9172, 0.468, -0.4527, -0.6604, -0.329, 2.8226, 2.8226, 2.811, 2.8052, 2.7944, 2.7005, 2.6404, 2.5817, 2.5475, 2.3172, 1.9812, 1.8614, 1.8611, 1.8534, 1.651, 1.6471, 1.633, 1.5192, 1.5134, 1.462, 1.3432, 1.3192, 1.2773, 1.276, 1.273, 1.2655, 1.2281, 1.1606, 1.1398, 0.9656, 0.7512, 0.0851, -0.1649, 0.5028, 0.4895, -0.6188, -0.9965, -0.5655, 0.1071], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1153, -4.6361, -4.0899, -4.7903, -4.2015, -4.692, -5.1326, -3.32, -5.323, -5.133, -4.3469, -5.0368, -5.5464, -3.2139, -5.3242, -5.1023, -5.1309, -2.9251, -3.811, -3.0109, -5.0664, -5.9367, -3.2272, -5.4831, -5.8013, -2.5898, -5.7214, -3.1045, -5.5089, -5.9455, -2.5212, -2.7738, -2.4972, -3.3918, -4.7272, -3.8922, -4.3948, -4.7911, -4.6956, -4.6328, -4.8344, -4.869, -4.9387, -5.0164, -3.6033, -4.1205, -1.9575, -2.5949, -4.7708, -4.4534, -3.8187, -3.9962, -3.6787, -4.9769, -4.2963, -5.1351, -5.1469, -5.0359, -5.0055, -4.7938, -5.3877, -3.8938, -4.5323, -4.0365, -5.7042, -5.3833, -5.0752, -4.8026, -5.1251, -5.579, -5.528, -5.7645, -4.4741, -4.4442, -3.5762, -3.1926, -3.1092, -2.4155, -4.8895, -3.2937, -3.9531, -4.0442, -3.6103, -4.5285, -4.6096, -4.6186, -4.9276, -2.7567, -3.973, -4.308, -4.4697, -4.1854, -3.37, -4.6024, -4.841, -4.73, -4.7418, -5.0585, -4.2398, -5.1005, -4.8516, -5.0198, -4.5092, -5.0164, -4.9233, -5.3639, -4.2811, -4.8362, -4.6927, -5.2843, -5.5588, -4.0833, -5.5113, -3.7352, -3.8517, -2.4482, -4.1727, -2.565, -3.7949, -4.0276, -3.5608, -4.1307, -2.6516, -4.4536, -3.594, -4.6863, -4.3383, -4.5592, -4.5484, -4.62, -4.7215, -4.744, -3.2455, -4.5633, -4.5221, -3.0883, -3.6852, -4.3032, -4.9646, -5.0964, -4.4172, -5.0621, -5.0766, -4.9902, -5.4373, -5.0051, -4.7476, -3.5029, -4.7324, -5.5594, -5.4273, -3.6783, -5.4741, -5.3106, -5.5219, -5.5445, -5.72, -5.6246, -4.6296, -5.414, -5.5979, -2.1432, -3.9645, -2.753, -3.0959, -2.7327, -4.3766, -3.4824, -2.5442, -4.0318, -4.6276, -4.5475, -4.1124, -4.5639, -4.4304, -4.4952, -4.8577, -3.7689, -4.0514, -4.5401, -4.5376, -3.9723, -4.6257, -4.572, -4.5592, -4.3179, -4.8475, -5.1229, -4.6239, -3.5418, -3.5056, -4.2484, -4.8076, -5.2226, -3.5615, -4.815, -3.4979, -4.8778, -4.6547, -4.5455, -5.4536, -4.881, -5.0313, -5.5291, -3.3068, -5.6198, -4.7543, -3.8316, -3.9826, -2.2302, -3.8659, -4.1379, -2.1827, -3.0276, -4.4028, -4.4945, -3.9726, -4.3519, -4.4771, -4.2873, -4.3959, -4.5791, -4.4403, -4.1054, -3.9539, -4.0637, -3.3657, -4.364, -4.5573, -3.1308, -4.0198, -4.4739, -4.9764, -4.9734, -4.3608, -5.2266, -5.0701, -4.0467, -3.2295, -4.5619, -4.9801, -5.029, -4.6771, -5.3668, -3.3264, -3.4134, -5.0801, -5.3645, -3.9974, -4.8933, -4.0237, -4.2477, -2.5535, -3.3637, -3.915, -4.2775, -3.2451, -3.8957, -3.8926, -4.3299, -4.3927, -2.4597, -4.3744, -4.4607, -4.4608, -2.59, -3.9756, -3.6235, -4.2143, -3.9291, -4.5762, -3.5534, -4.5627, -4.3747, -3.2792, -5.0057, -4.8784, -2.4796, -4.3449, -2.9558, -5.3406, -4.7328, -5.2645, -5.7392, -5.1339, -3.6069, -4.0514, -4.6297, -6.1257, -4.368, -5.328, -4.769, -2.81, -2.2726, -2.7653, -3.3163, -4.6175, -4.0857, -4.0857, -3.6678, -2.8583, -4.3463, -4.356, -4.1089, -4.5243, -4.4838, -4.5947, -4.772, -3.3641, -4.3999, -4.4304, -3.5948, -4.6297, -5.0521, -4.9236, -4.3903, -4.3661, -4.2931, -4.5372, -4.6178, -4.4576, -4.5152, -5.1385, -4.5313, -3.9082, -4.8585, -5.1699, -3.9213, -3.7876, -3.9476, -3.3424, -1.995, -3.6677, -3.5775, -3.5021, -3.8006, -3.3713, -3.6918, -4.4435, -3.7205, -3.2698, -4.1738, -3.7247, -4.0754, -4.2813, -4.3768, -3.9358, -4.0063, -3.9426, -3.2449, -3.3289, -3.0018, -4.436, -4.7516, -4.621, -4.6501, -3.9639, -3.0059, -5.0242, -4.6275, -4.2248, -4.6973, -4.3124, -4.8949, -3.0691, -5.2209, -5.2534, -4.9963, -5.5547, -3.3232, -2.4089, -2.9982, -2.4274, -4.4691, -4.3705, -4.3692, -4.3479, -4.5189, -3.6097, -3.6097, -3.8159, -3.8961, -2.087, -2.2026, -3.9878, -4.2967, -4.0061, -4.3981, -3.8211, -3.2479, -4.7907, -3.1008, -4.8692, -3.6076, -3.5836, -4.5202, -4.724, -4.5435, -4.0033, -5.3848, -5.6466, -4.8077, -5.1914, -4.4223, -4.8094, -4.9657, -3.958, -5.467, -4.4434, -2.8781, -2.5744, -4.424, -4.5267, -4.1642, -4.4875, -4.6411, -4.7451]}, \"token.table\": {\"Topic\": [3, 5, 8, 3, 5, 6, 9, 10, 4, 1, 5, 7, 4, 6, 3, 5, 7, 3, 6, 3, 4, 9, 3, 7, 9, 10, 1, 2, 3, 5, 6, 8, 1, 4, 6, 7, 10, 3, 4, 5, 6, 7, 10, 4, 6, 1, 2, 4, 5, 6, 7, 5, 8, 3, 6, 1, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 7, 6, 2, 4, 5, 8, 6, 7, 8, 1, 2, 6, 9, 10, 3, 5, 6, 7, 8, 9, 2, 5, 6, 8, 5, 7, 8, 10, 4, 5, 7, 8, 4, 5, 9, 3, 6, 2, 4, 8, 4, 9, 10, 1, 3, 6, 7, 1, 2, 6, 9, 2, 3, 4, 9, 2, 3, 1, 2, 9, 10, 1, 3, 4, 1, 2, 3, 5, 3, 4, 7, 2, 6, 3, 5, 6, 8, 1, 3, 8, 1, 2, 7, 1, 2, 3, 4, 6, 9, 10, 3, 4, 8, 9, 10, 1, 5, 4, 9, 1, 3, 6, 4, 5, 1, 2, 4, 5, 6, 8, 10, 5, 9, 10, 2, 6, 8, 9, 1, 3, 4, 9, 1, 3, 9, 2, 3, 4, 2, 7, 2, 4, 2, 7, 8, 10, 1, 2, 5, 8, 1, 2, 3, 5, 7, 1, 3, 8, 10, 1, 4, 6, 10, 3, 6, 2, 3, 7, 8, 2, 3, 5, 2, 5, 6, 8, 10, 2, 4, 5, 6, 2, 4, 6, 1, 2, 4, 6, 4, 6, 1, 2, 4, 5, 7, 10, 3, 4, 5, 10, 1, 4, 5, 6, 9, 1, 5, 6, 7, 1, 5, 8, 9, 5, 6, 7, 8, 10, 2, 6, 10, 2, 3, 4, 7, 1, 2, 3, 2, 6, 3, 4, 6, 8, 1, 2, 3, 5, 5, 2, 3, 4, 5, 7, 7, 3, 4, 8, 9, 10, 3, 4, 5, 8, 3, 5, 1, 3, 5, 6, 9, 10, 3, 1, 2, 5, 9, 2, 8, 10, 2, 3, 4, 1, 8, 9, 1, 2, 5, 6, 10, 2, 4, 5, 4, 8, 9, 6, 8, 1, 2, 3, 4, 10, 1, 4, 5, 6, 7, 7, 3, 6, 1, 2, 4, 5, 7, 8, 9, 1, 3, 4, 5, 9, 2, 6, 1, 2, 4, 2, 4, 10, 2, 8, 6, 9, 10, 1, 7, 8, 3, 6, 10, 2, 3, 4, 5, 1, 8, 1, 7, 10, 1, 2, 4, 5, 6, 1, 2, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 3, 4, 10, 2, 5, 6, 10, 3, 7, 2, 6, 8, 3, 2, 5, 6, 3, 9, 10, 2, 3, 10, 2, 3, 4, 5, 6, 3, 1, 2, 3, 4, 5, 6, 9, 4, 6, 7, 8, 1, 6, 2, 3, 4, 6, 8, 2, 3, 4, 2, 3, 8, 5, 6, 7, 8, 6, 8, 1, 2, 5, 7, 8, 7, 9, 1, 2, 6, 7, 6, 7, 1, 3, 5, 6, 7, 8, 1, 3, 4, 5, 8, 9, 10, 1, 2, 4, 5, 6, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 8, 2, 8, 9, 1, 4, 1, 2, 5, 6, 7, 9, 1, 3, 10, 3, 10, 3, 5, 6, 2, 3, 5, 7, 8, 10, 1, 2, 5, 3, 6, 3, 6, 9, 3, 6, 4, 5, 6, 9, 1, 2, 3, 5, 6, 10, 3, 4, 6, 8, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 2, 6, 7, 8, 3, 6, 2, 8, 3, 5, 2, 1, 2, 3, 4, 9, 9, 2, 3, 5, 6, 8, 9, 10, 7, 4, 6, 8, 7, 8, 1, 5, 7, 1, 3, 7, 1, 2, 3, 9, 1, 2, 3, 6, 8, 9, 2, 3, 2, 6, 8, 10, 5, 6, 8, 3, 8, 3, 5, 6, 2, 3, 4, 6, 10, 1, 2, 6, 8, 5, 6, 7, 8, 4, 5, 9, 8, 6, 7, 1, 7, 9, 1, 2, 3, 6, 8, 10, 6, 7, 8, 6, 7, 3, 4, 5, 6, 7, 8, 3, 4, 6, 1, 4, 5, 6, 3, 4, 5, 8, 3, 9, 1, 3, 1, 1, 3, 4, 5, 6, 8, 9, 10, 2, 4, 8, 9, 4, 5, 8, 1, 2, 3, 6, 9, 10, 3, 6, 7, 9, 2, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 1, 3, 4, 5, 8, 9, 4, 9, 1, 2, 3, 6, 7, 10, 3, 6, 1, 4, 5, 6, 9, 1, 5, 3, 7, 1, 4, 6, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 10, 3, 3, 6, 8, 10, 2, 2, 4, 5, 6, 7, 4, 9, 10, 5, 2, 3, 4, 8, 1, 6, 10, 2, 9, 1, 2, 4, 6, 7, 9, 10, 5, 6, 9], \"Freq\": [0.15799689144045218, 0.47399067432135655, 0.31599378288090435, 0.3675761888394711, 0.21720411158696018, 0.2339121201705725, 0.03341601716722464, 0.11695606008528625, 0.9193755889811351, 0.09374927475789627, 0.6562449233052738, 0.18749854951579253, 0.674974542370416, 0.29530136228705695, 0.5726250543836919, 0.28631252719184597, 0.1145250108767384, 0.23353239104901272, 0.7430576078832223, 0.18543009025321286, 0.24724012033761714, 0.4944802406752343, 0.15596410270097757, 0.37431384648234617, 0.37431384648234617, 0.062385641080391026, 0.179979813076875, 0.13498485980765623, 0.10498822429484375, 0.4649478504485937, 0.0899899065384375, 0.014998317756406249, 0.10616054980223884, 0.09099475697334758, 0.09099475697334758, 0.5308027490111942, 0.18198951394669516, 0.4120696965093891, 0.047093679601073045, 0.14128103880321913, 0.3885228567088526, 0.8947680904395943, 0.08947680904395942, 0.36888768727467103, 0.4611096090933388, 0.1516210978158952, 0.0758105489079476, 0.030324219563179038, 0.3032421956317904, 0.0758105489079476, 0.3714716896489432, 0.7726915598642821, 0.2207690171040806, 0.8110843065597447, 0.16221686131194896, 0.3878154976513712, 0.3878154976513712, 0.2326892985908227, 0.22579092866924402, 0.12071990245682353, 0.04247552123480828, 0.1676665311900327, 0.26155978865645096, 0.04694662873320915, 0.1251910099552244, 0.008942214996801742, 0.7462499863336481, 0.012866379074718071, 0.012866379074718071, 0.20586206519548914, 0.9476544072069613, 0.22338902131177696, 0.4467780426235539, 0.17871121704942156, 0.08935560852471078, 0.23444487309936377, 0.07814829103312126, 0.6251863282649701, 0.26316807057604963, 0.22557263192232826, 0.11278631596116413, 0.11278631596116413, 0.22557263192232826, 0.08096052851794099, 0.14168092490639672, 0.18216118916536722, 0.10120066064742624, 0.32384211407176394, 0.14168092490639672, 0.19619560022907304, 0.2452445002863413, 0.09809780011453652, 0.39239120045814607, 0.07270237853614085, 0.07270237853614085, 0.7997261638975494, 0.9216848283409519, 0.1806631235878494, 0.2408841647837992, 0.42154728837164857, 0.1204420823918996, 0.2672074419957939, 0.6680186049894847, 0.04453457366596565, 0.16288623345289135, 0.773709608901234, 0.39660543333007287, 0.07932108666601458, 0.4759265199960874, 0.3023389448603188, 0.45350841729047825, 0.22675420864523912, 0.4665636633880109, 0.09331273267760218, 0.13996909901640328, 0.27993819803280656, 0.16316338227850175, 0.6118626835443816, 0.12237253670887631, 0.08158169113925087, 0.8398487224988059, 0.026245272578087685, 0.05249054515617537, 0.05249054515617537, 0.6459977625845823, 0.2422491609692184, 0.15512183591979684, 0.8376579139669028, 0.2601274901872983, 0.7153505980150704, 0.11942021116884394, 0.11942021116884394, 0.7165212670130636, 0.46943127395547607, 0.04694312739554761, 0.14082938218664282, 0.32860189176883325, 0.07853076505374874, 0.3926538252687437, 0.47118459032249244, 0.20501509954120817, 0.7517220316510966, 0.1532535933086197, 0.20433812441149293, 0.3065071866172394, 0.3235353636515305, 0.19958212965620498, 0.13305475310413667, 0.6430979733366605, 0.20573781853747483, 0.06857927284582495, 0.6857927284582495, 0.15371826365265656, 0.05123942121755219, 0.17079807072517397, 0.23911729901524356, 0.034159614145034795, 0.05123942121755219, 0.29035672023279574, 0.12281282696643571, 0.12281282696643571, 0.061406413483217855, 0.6140641348321786, 0.9046272262688443, 0.7484648806453588, 0.1871162201613397, 0.5793837742069199, 0.33107644240395423, 0.7330721816686465, 0.07330721816686465, 0.1466144363337293, 0.24179996156808486, 0.6649498943122334, 0.08084102528425956, 0.3435743574581031, 0.10105128160532445, 0.12126153792638933, 0.2021025632106489, 0.02021025632106489, 0.08084102528425956, 0.5824962693487005, 0.31772523782656387, 0.10590841260885463, 0.42184429156615066, 0.2812295277107671, 0.23435793975897257, 0.04687158795179452, 0.2558164728665045, 0.03654521040950064, 0.10963563122850192, 0.5847233665520103, 0.1268187395879127, 0.6340936979395635, 0.19022810938186904, 0.21819562022639283, 0.06818613132074776, 0.7091357657357767, 0.8123921338875464, 0.175652353272983, 0.9450915979057916, 0.052023390710410546, 0.6245456847252829, 0.06939396496947588, 0.06939396496947588, 0.13878792993895175, 0.05230183921379833, 0.62762207056558, 0.05230183921379833, 0.20920735685519332, 0.5889465204758239, 0.12685001979479282, 0.0453035784981403, 0.009060715699628059, 0.22651789249070148, 0.12578945979700526, 0.06289472989850263, 0.503157839188021, 0.3144736494925131, 0.21521715591807755, 0.14347810394538504, 0.21521715591807755, 0.35869525986346257, 0.47168816562704735, 0.47168816562704735, 0.2947989680087865, 0.22109922600658988, 0.07369974200219663, 0.3684987100109831, 0.2970616188525879, 0.5198578329920288, 0.14853080942629396, 0.16259931074943898, 0.08129965537471949, 0.08129965537471949, 0.4471481045609572, 0.20324913843679873, 0.3239437143457472, 0.22676060004202303, 0.38873245721489663, 0.03239437143457472, 0.1275433819033122, 0.3826301457099366, 0.44640183666159267, 0.14125053976888294, 0.42375161930664884, 0.14125053976888294, 0.2825010795377659, 0.22541135018017167, 0.7325868880855578, 0.17240058989623472, 0.3663512535294988, 0.19395066363326408, 0.19395066363326408, 0.02155007373702934, 0.06465022121108803, 0.11896240180927349, 0.47584960723709396, 0.17844360271391024, 0.17844360271391024, 0.4454549896380457, 0.06186874856083968, 0.4083337405015419, 0.03712124913650381, 0.03712124913650381, 0.3424274027952806, 0.13697096111811224, 0.13697096111811224, 0.3424274027952806, 0.05533679300053501, 0.22134717200214005, 0.27668396500267506, 0.4426943440042801, 0.1812773465508153, 0.06797900495655573, 0.2039370148696672, 0.521172371333594, 0.04531933663770382, 0.6592649488167516, 0.09418070697382167, 0.18836141394764333, 0.078380317421939, 0.078380317421939, 0.627042539375512, 0.156760634843878, 0.5726592033779884, 0.057265920337798835, 0.2863296016889942, 0.3253123774666184, 0.6506247549332368, 0.1908365320373161, 0.06361217734577203, 0.4452852414204042, 0.2544487093830881, 0.05282428008297576, 0.898012761410588, 0.6626533581877342, 0.294512603638993, 0.9578731824129258, 0.07275691345228637, 0.21827074035685912, 0.7033168300387682, 0.09786232659464685, 0.8807609393518216, 0.9474688862252346, 0.14219904492453359, 0.1895987265660448, 0.1895987265660448, 0.1895987265660448, 0.23699840820755597, 0.4998292648884567, 0.19993170595538268, 0.12495731622211417, 0.17494024271095984, 0.5896614910643376, 0.368538431915211, 0.10646598955984464, 0.42586395823937856, 0.01774433159330744, 0.10646598955984464, 0.01774433159330744, 0.3016536370862265, 0.9809677733287872, 0.1698768451110262, 0.40770442826646286, 0.06795073804441047, 0.3397536902220524, 0.5499241693204961, 0.35956580301724744, 0.0846037183569994, 0.2416763570142872, 0.2416763570142872, 0.4833527140285744, 0.05600875595505182, 0.7841225833707255, 0.16802626786515545, 0.12271625118755777, 0.12271625118755777, 0.276111565172005, 0.030679062796889443, 0.39882781635956277, 0.4698000176659148, 0.4698000176659148, 0.9356315925598409, 0.19828684179064437, 0.33047806965107396, 0.39657368358128875, 0.5922006458485459, 0.33840036905631193, 0.3679810992797652, 0.006082332219500251, 0.3801457637187657, 0.22200512601175915, 0.02128816276825088, 0.144360649322917, 0.42105189385850794, 0.288721298645834, 0.03609016233072925, 0.10827048699218775, 0.9900899024722616, 0.7057644949855099, 0.19248122590513905, 0.17852822061662127, 0.07141128824664851, 0.2618413902377112, 0.07141128824664851, 0.011901881374441418, 0.023803762748882837, 0.3808602039821254, 0.21987415149554362, 0.11839377388221581, 0.10148037761332783, 0.11839377388221581, 0.4228349067221993, 0.6524467961880198, 0.3262233980940099, 0.104729015114522, 0.6981934340968133, 0.17454835852420333, 0.41088855380500716, 0.479369979439175, 0.06848142563416786, 0.7242612005042846, 0.24142040016809485, 0.07006823241292007, 0.07006823241292007, 0.7707505565421208, 0.11398471679169195, 0.7978930175418436, 0.056992358395845974, 0.30097151863014954, 0.4924988486675174, 0.19152733003736788, 0.16442176051022536, 0.2055272006377817, 0.4110544012755634, 0.16442176051022536, 0.3968057536230645, 0.5668653623186636, 0.9553762504495485, 0.7635388632222792, 0.16967530293828426, 0.07359509432706146, 0.22078528298118436, 0.29438037730824584, 0.29438037730824584, 0.07359509432706146, 0.12969975913708467, 0.17833716881349143, 0.0972748193528135, 0.5350115064404742, 0.06484987956854234, 0.23322977760054192, 0.06996893328016257, 0.07176300849247444, 0.24220015366210124, 0.09508598625252863, 0.06996893328016257, 0.10585043752639979, 0.050234105944732106, 0.06099855721860327, 0.23287270042968974, 0.038812116738281624, 0.5433696343359428, 0.1940605836914081, 0.13829365210047825, 0.8297619126028695, 0.3822037356479948, 0.5350852299071928, 0.10273523300219847, 0.8561269416849873, 0.12764936268215224, 0.4680476631678916, 0.38294808804645675, 0.9875046187711433, 0.17100142127354992, 0.17100142127354992, 0.5985049744574247, 0.012215731834098622, 0.06107865917049311, 0.9283956193914953, 0.02496719796268832, 0.12483598981344161, 0.8364011317500588, 0.03319822954098625, 0.43157698403282124, 0.0663964590819725, 0.26558583632789, 0.132792918163945, 0.9726752066517317, 0.032269955525398936, 0.032269955525398936, 0.3307670441353391, 0.16134977762699468, 0.032269955525398936, 0.16134977762699468, 0.24202466644049203, 0.18466034789110114, 0.18466034789110114, 0.09233017394555057, 0.4616508697277528, 0.8952352591121826, 0.06631372289719871, 0.12268206552747331, 0.1635760873699644, 0.12268206552747331, 0.1635760873699644, 0.408940218424911, 0.13642146997494276, 0.34105367493735694, 0.4774751449122997, 0.09314465843639638, 0.2794339753091892, 0.46572329218198194, 0.1572728685267455, 0.2359093027901182, 0.314545737053491, 0.2359093027901182, 0.8122423455476385, 0.13537372425793975, 0.19795012618112517, 0.19795012618112517, 0.07918005047245008, 0.19795012618112517, 0.35631022712602534, 0.6341263207728873, 0.31706316038644367, 0.3733429545011925, 0.09333573862529812, 0.28000721587589433, 0.09333573862529812, 0.8135438557436944, 0.13559064262394907, 0.16428866661454924, 0.08214433330727462, 0.3285773332290985, 0.16428866661454924, 0.12321649996091193, 0.12321649996091193, 0.027955958012207474, 0.3634274541586972, 0.16773574807324484, 0.27955958012207477, 0.027955958012207474, 0.04193393701831121, 0.09784585304272617, 0.12993596607169214, 0.4547758812509225, 0.06496798303584607, 0.1949039491075382, 0.1949039491075382, 0.6992228997966335, 0.06992228997966335, 0.1398445799593267, 0.391533339271985, 0.15906041907924393, 0.0917656263918715, 0.08564791796574672, 0.06117708426124766, 0.04894166740899813, 0.012235416852249532, 0.11011875167024579, 0.04282395898287336, 0.04418448648964047, 0.9278742162824499, 0.11178860038269126, 0.5589430019134562, 0.2794715009567281, 0.1957758100123312, 0.8009010409595366, 0.32780728917591223, 0.046829612739416035, 0.42146651465474433, 0.046829612739416035, 0.09365922547883207, 0.046829612739416035, 0.5879149792040499, 0.3674468620025312, 0.9216848538827221, 0.9167087764221888, 0.0733367021137751, 0.4404080725364589, 0.3670067271137158, 0.1468026908454863, 0.06136950019749692, 0.199450875641865, 0.15342375049374232, 0.1841085005924908, 0.03068475009874846, 0.3682170011849816, 0.5643091096233788, 0.18810303654112626, 0.18810303654112626, 0.27511123299012286, 0.7120526030332591, 0.6628478059232409, 0.03156418123444004, 0.28407763110996037, 0.17709627231675307, 0.7526591573462005, 0.38351024263623656, 0.11902042012848721, 0.06612245562693733, 0.42318371601239896, 0.09195939617367847, 0.026274113192479562, 0.40724875448343323, 0.06568528298119891, 0.03941116978871934, 0.3547005280984741, 0.5348638644743252, 0.14587196303845232, 0.19449595071793643, 0.04862398767948411, 0.04862398767948411, 0.9097725902767769, 0.13716307232814723, 0.13406916844104616, 0.10519273216143621, 0.09281711661303195, 0.12685005937114366, 0.08147280236032804, 0.09900492438723409, 0.11550574511843976, 0.058784173854920234, 0.04743985960221633, 0.2914702044208273, 0.6558079599468614, 0.08175864637823099, 0.5314312014585014, 0.32703458551292397, 0.040879323189115496, 0.15648738089729775, 0.7824369044864887, 0.14604401571744596, 0.8032420864459527, 0.662733577540783, 0.29454825668479245, 0.9062107779599105, 0.3352689573281237, 0.2793907977734364, 0.06519118614713515, 0.1629779653678379, 0.14900842547916607, 0.9620250592516628, 0.0305226689309248, 0.3510106927056352, 0.2594426859128608, 0.2136586825164736, 0.0305226689309248, 0.0457840033963872, 0.0610453378618496, 0.9408159638742104, 0.7590124701831195, 0.18975311754577986, 0.9472848681629708, 0.2777325657747995, 0.6480426534745322, 0.17201297371575686, 0.6307142369577751, 0.11467531581050457, 0.18446490078643638, 0.1054085147351065, 0.7115074744619688, 0.23025066143472642, 0.07675022047824215, 0.19187555119560537, 0.49887643310857394, 0.1318099652924301, 0.33776303606185215, 0.016476245661553764, 0.08238122830776881, 0.23890556209252956, 0.18947682510786829, 0.2730872958331542, 0.710026969166201, 0.09723675794114751, 0.3694996801763606, 0.3111576254116721, 0.21392086747052452, 0.4968773919385891, 0.1863290219769709, 0.31054836996161816, 0.23499033612645392, 0.7049710083793618, 0.6291268688591692, 0.22877340685787972, 0.05719335171446993, 0.6157773963222374, 0.038486087270139836, 0.1154582618104195, 0.1154582618104195, 0.1154582618104195, 0.09280393237662214, 0.09280393237662214, 0.37121572950648857, 0.4176176956947997, 0.29239623676321064, 0.14619811838160532, 0.14619811838160532, 0.36549529595401326, 0.14540626603878407, 0.6543281971745283, 0.14540626603878407, 0.9472848331234115, 0.8234083902393303, 0.14530736298341124, 0.3973273680834871, 0.07946547361669742, 0.5165255785085333, 0.10722368840046431, 0.10722368840046431, 0.16083553260069647, 0.16083553260069647, 0.32167106520139294, 0.16083553260069647, 0.39763744026582, 0.08836387561462666, 0.4418193780731333, 0.15759462343989475, 0.7879731171994737, 0.36328419117034005, 0.055043059268233344, 0.15412056595105336, 0.3963100267312801, 0.011008611853646669, 0.022017223707293337, 0.31320706178869206, 0.3915088272358651, 0.23490529634151905, 0.0850941597877287, 0.1701883195754574, 0.25528247936318615, 0.42547079893864354, 0.2707483059336004, 0.05414966118672008, 0.48734695068048073, 0.10829932237344016, 0.45607149624733073, 0.49753254136072445, 0.835734501191875, 0.06428726932245192, 0.9680342664984118, 0.17342037755677667, 0.35647522053337427, 0.041749350152557346, 0.01605744236636821, 0.11240209656457748, 0.08028721183184105, 0.18626633144987123, 0.02890339625946278, 0.06615737867692859, 0.26462951470771434, 0.19847213603078578, 0.39694427206157157, 0.06862823308063698, 0.7549105638870067, 0.13725646616127396, 0.10677421114575054, 0.1779570185762509, 0.10677421114575054, 0.4745520495366691, 0.07118280743050036, 0.059319006192083634, 0.4190254388842584, 0.35916466190079294, 0.05986077698346549, 0.11972155396693097, 0.1189620005362709, 0.06797828602072623, 0.7987448607435331, 0.4494089442765603, 0.14463736137636424, 0.06715306063902625, 0.09814678093396145, 0.020662480196623464, 0.06715306063902625, 0.015496860147467597, 0.11880926113058492, 0.020662480196623464, 0.25919792449862966, 0.38879688674794444, 0.12959896224931483, 0.19439844337397222, 0.15212692923620846, 0.09361657183766675, 0.14042485775650013, 0.2691476440332919, 0.24574350107387521, 0.09361657183766675, 0.2982766998250762, 0.6779015905115368, 0.43113347091384335, 0.005457385707770169, 0.03274431424662101, 0.06548862849324202, 0.4256760852060732, 0.03274431424662101, 0.27441721347557335, 0.705644263222903, 0.24356211730621527, 0.06958917637320436, 0.5567134109856349, 0.06958917637320436, 0.05219188227990327, 0.8520302127444809, 0.10650377659306011, 0.9591727964767648, 0.9408173399917437, 0.7887761897808793, 0.07887761897808793, 0.07887761897808793, 0.64194599740237, 0.33625742721076524, 0.12215827736665592, 0.24061478875250408, 0.05552648971211633, 0.19249183100200326, 0.07773708559696285, 0.07773708559696285, 0.12586004334746367, 0.07773708559696285, 0.02961412784646204, 0.003701765980807755, 0.17997674506257802, 0.7199069802503121, 0.9446841045051039, 0.34999038619387574, 0.19443910344104207, 0.19443910344104207, 0.2722147448174589, 0.9773543708056041, 0.9855990879419588, 0.340336418641378, 0.2552523139810335, 0.170168209320689, 0.170168209320689, 0.2881189738340108, 0.5186141529012195, 0.1728713843004065, 0.9541597908379834, 0.054136449939620856, 0.7037738492150711, 0.054136449939620856, 0.16240934981886257, 0.8547379268005726, 0.056982528453371505, 0.056982528453371505, 0.9588115192286073, 0.037235398804994456, 0.09194388245431058, 0.055166329472586345, 0.20227654139948326, 0.09194388245431058, 0.055166329472586345, 0.42294185928982864, 0.055166329472586345, 0.3785699750154802, 0.04732124687693502, 0.5205337156462853], \"Term\": [\"accuracy\", \"accuracy\", \"accuracy\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"addition\", \"adopt\", \"adopt\", \"adopt\", \"advance\", \"advance\", \"analysis\", \"analysis\", \"analysis\", \"answer\", \"answer\", \"application\", \"application\", \"application\", \"apply\", \"apply\", \"apply\", \"apply\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"art\", \"art\", \"art\", \"art\", \"attention\", \"attention\", \"available\", \"available\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"baseline\", \"baseline\", \"benchmark\", \"benchmark\", \"benefit\", \"benefit\", \"benefit\", \"bert\", \"bert\", \"bert\", \"bert\", \"bert\", \"bert\", \"bert\", \"bert\", \"bidirectional\", \"bidirectional\", \"bidirectional\", \"bidirectional\", \"block\", \"build\", \"build\", \"build\", \"build\", \"candidate\", \"candidate\", \"candidate\", \"capture\", \"capture\", \"capture\", \"capture\", \"capture\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"cls\", \"cls\", \"cls\", \"cnn\", \"combine\", \"combine\", \"combine\", \"combine\", \"compare\", \"compare\", \"compare\", \"comprehension\", \"comprehension\", \"compute\", \"compute\", \"compute\", \"computer\", \"computer\", \"computer\", \"consider\", \"consider\", \"consider\", \"consider\", \"context\", \"context\", \"context\", \"context\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextualize\", \"contextualize\", \"contextualized\", \"contextualized\", \"convolutional\", \"convolutional\", \"corpora\", \"corpora\", \"corpora\", \"corpus\", \"corpus\", \"corpus\", \"corpus\", \"cross\", \"cross\", \"cross\", \"current\", \"current\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"decoder\", \"decoder\", \"decoder\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"dependency\", \"design\", \"design\", \"detection\", \"detection\", \"develop\", \"develop\", \"develop\", \"development\", \"development\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"dnn\", \"dnn\", \"dnn\", \"document\", \"document\", \"document\", \"document\", \"downstream\", \"downstream\", \"downstream\", \"downstream\", \"effective\", \"effective\", \"effective\", \"elmo\", \"elmo\", \"elmo\", \"embed\", \"embed\", \"embedding\", \"embedding\", \"employ\", \"employ\", \"employ\", \"employ\", \"encode\", \"encode\", \"encode\", \"encode\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"end\", \"end\", \"end\", \"end\", \"english\", \"english\", \"english\", \"english\", \"entailment\", \"entailment\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluate\", \"evaluation\", \"evaluation\", \"evaluation\", \"example\", \"example\", \"example\", \"example\", \"example\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"explore\", \"explore\", \"explore\", \"extract\", \"extract\", \"extract\", \"extract\", \"extraction\", \"extraction\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"field\", \"field\", \"field\", \"field\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"finetune\", \"finetune\", \"finetune\", \"finetune\", \"focus\", \"focus\", \"focus\", \"focus\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"form\", \"form\", \"form\", \"framework\", \"framework\", \"framework\", \"framework\", \"general\", \"general\", \"general\", \"generate\", \"generate\", \"generation\", \"generation\", \"generation\", \"generation\", \"glove\", \"glove\", \"glue\", \"glue\", \"good\", \"gpt\", \"gpt\", \"gpt\", \"head\", \"head\", \"hidden\", \"image\", \"image\", \"image\", \"image\", \"image\", \"improve\", \"improve\", \"improve\", \"improve\", \"improvement\", \"improvement\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"inspire\", \"inspire\", \"inspire\", \"instance\", \"instance\", \"instance\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"investigate\", \"investigate\", \"knowledge\", \"label\", \"label\", \"label\", \"labeling\", \"labeling\", \"language\", \"language\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"large\", \"layer\", \"lead\", \"lead\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"length\", \"length\", \"level\", \"level\", \"level\", \"leverage\", \"leverage\", \"leverage\", \"linguistic\", \"linguistic\", \"long\", \"long\", \"long\", \"lstm\", \"lstm\", \"lstm\", \"machine\", \"machine\", \"machine\", \"make\", \"make\", \"make\", \"make\", \"mask\", \"mask\", \"masked\", \"mechanism\", \"mechanism\", \"mention\", \"mention\", \"mention\", \"mention\", \"mention\", \"method\", \"method\", \"method\", \"method\", \"method\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"module\", \"module\", \"mrc\", \"mrc\", \"multi\", \"multi\", \"multiple\", \"multiple\", \"multiple\", \"natural\", \"ner\", \"ner\", \"ner\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nli\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"number\", \"number\", \"number\", \"number\", \"objective\", \"objective\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"openai\", \"openai\", \"openai\", \"order\", \"order\", \"order\", \"original\", \"original\", \"original\", \"original\", \"pair\", \"pair\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"parameter\", \"parameter\", \"particular\", \"particular\", \"particular\", \"particular\", \"passage\", \"passage\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"popular\", \"popular\", \"popular\", \"popular\", \"popular\", \"position\", \"position\", \"position\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"predict\", \"predict\", \"prediction\", \"prediction\", \"prediction\", \"pretraine\", \"pretraine\", \"pretrained\", \"pretrained\", \"pretrained\", \"pretrained\", \"pretrained\", \"pretrained\", \"previous\", \"previous\", \"problem\", \"processing\", \"processing\", \"progress\", \"progress\", \"progress\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"purpose\", \"purpose\", \"purpose\", \"question\", \"question\", \"range\", \"range\", \"range\", \"read\", \"read\", \"recent\", \"recent\", \"recent\", \"recent\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recurrent\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"ref\", \"refer\", \"refer\", \"relation\", \"relation\", \"relation\", \"relation\", \"release\", \"release\", \"replace\", \"replace\", \"report\", \"report\", \"represent\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"research\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"rnn\", \"scale\", \"scale\", \"score\", \"second\", \"second\", \"section\", \"section\", \"section\", \"self\", \"self\", \"self\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentiment\", \"sentiment\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"set\", \"set\", \"set\", \"setting\", \"setting\", \"significant\", \"significant\", \"significant\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"single\", \"single\", \"single\", \"single\", \"size\", \"size\", \"size\", \"size\", \"small\", \"small\", \"small\", \"source\", \"span\", \"span\", \"specific\", \"specific\", \"specific\", \"specifically\", \"specifically\", \"specifically\", \"specifically\", \"specifically\", \"specifically\", \"squad\", \"squad\", \"squad\", \"standard\", \"standard\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"step\", \"step\", \"step\", \"structure\", \"structure\", \"structure\", \"structure\", \"study\", \"study\", \"study\", \"study\", \"success\", \"success\", \"supervise\", \"supervise\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"technique\", \"technique\", \"technique\", \"technique\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"textual\", \"textual\", \"textual\", \"textual\", \"token\", \"token\", \"token\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"trained\", \"trained\", \"trained\", \"trained\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transfer\", \"transfer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"translation\", \"translation\", \"tune\", \"tune\", \"tune\", \"tune\", \"tune\", \"tuning\", \"tuning\", \"understanding\", \"unit\", \"universal\", \"universal\", \"universal\", \"unsupervised\", \"unsupervised\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"variant\", \"variant\", \"variety\", \"various\", \"various\", \"various\", \"various\", \"vec\", \"vector\", \"version\", \"version\", \"version\", \"version\", \"vision\", \"vision\", \"vision\", \"way\", \"wide\", \"wide\", \"wide\", \"wide\", \"wikipedia\", \"wikipedia\", \"wikipedia\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 6, 3, 5, 8, 9, 10, 7, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2471947929584324651178188\", ldavis_el2471947929584324651178188_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2471947929584324651178188\", ldavis_el2471947929584324651178188_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2471947929584324651178188\", ldavis_el2471947929584324651178188_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "3     -169.940063  -99.342064       1        1  14.948701\n",
       "0      -50.139137  -26.852158       2        1  13.507425\n",
       "5      -45.704956  113.090271       3        1  13.425670\n",
       "2      156.793930 -147.892059       4        1  10.637171\n",
       "4     -159.486572   37.086742       5        1  10.123688\n",
       "7      -65.489410 -165.081390       6        1   9.364552\n",
       "8      167.257156  -11.461771       7        1   8.665378\n",
       "9       43.013332 -223.894928       8        1   7.658154\n",
       "6       47.459114  -83.935799       9        1   6.026358\n",
       "1       62.816349   54.302124      10        1   5.642904, topic_info=    Category        Freq            Term       Total  loglift  logprob\n",
       "241  Default  214.000000            word  214.000000  30.0000  30.0000\n",
       "106  Default  328.000000        language  328.000000  29.0000  29.0000\n",
       "133  Default   81.000000         network   81.000000  28.0000  28.0000\n",
       "134  Default   80.000000          neural   80.000000  27.0000  27.0000\n",
       "222  Default  183.000000     transformer  183.000000  26.0000  26.0000\n",
       "60   Default  115.000000       embedding  115.000000  25.0000  25.0000\n",
       "108  Default   80.000000           layer   80.000000  24.0000  24.0000\n",
       "212  Default  311.000000            task  311.000000  23.0000  23.0000\n",
       "131  Default   93.000000         natural   93.000000  22.0000  22.0000\n",
       "18   Default  447.000000            bert  447.000000  21.0000  21.0000\n",
       "12   Default   78.000000       attention   78.000000  20.0000  20.0000\n",
       "179  Default  214.000000  representation  214.000000  19.0000  19.0000\n",
       "125  Default  557.000000           model  557.000000  18.0000  18.0000\n",
       "217  Default   58.000000           token   58.000000  17.0000  17.0000\n",
       "14   Default  131.000000            base  131.000000  16.0000  16.0000\n",
       "168  Default   75.000000          recent   75.000000  15.0000  15.0000\n",
       "189  Default  121.000000        sentence  121.000000  14.0000  14.0000\n",
       "58   Default   73.000000            elmo   73.000000  13.0000  13.0000\n",
       "137  Default  123.000000             nlp  123.000000  12.0000  12.0000\n",
       "165  Default   61.000000        question   61.000000  11.0000  11.0000\n",
       "63   Default  110.000000         encoder  110.000000  10.0000  10.0000\n",
       "169  Default   76.000000        recently   76.000000   9.0000   9.0000\n",
       "110  Default   84.000000           learn   84.000000   8.0000   8.0000\n",
       "19   Default   77.000000   bidirectional   77.000000   7.0000   7.0000\n",
       "156  Default   56.000000       pretraine   56.000000   6.0000   6.0000\n",
       "160  Default   54.000000      processing   54.000000   5.0000   5.0000\n",
       "11   Default   84.000000             art   84.000000   4.0000   4.0000\n",
       "205  Default   90.000000           state   90.000000   3.0000   3.0000\n",
       "172  Default  969.000000             ref  969.000000   2.0000   2.0000\n",
       "10   Default   65.000000    architecture   65.000000   1.0000   1.0000\n",
       "..       ...         ...             ...         ...      ...      ...\n",
       "128  Topic10    7.490541             mrc   13.082028   2.3172  -4.3981\n",
       "101  Topic10   13.338246       introduce   32.595520   1.9812  -3.8211\n",
       "162  Topic10   23.660327         propose   65.178957   1.8614  -3.2479\n",
       "65   Topic10    5.058295         english   13.939409   1.8611  -4.7907\n",
       "169  Topic10   27.410914        recently   76.120552   1.8534  -3.1008\n",
       "64   Topic10    4.676420             end   15.899583   1.6510  -4.8692\n",
       "95   Topic10   16.511350         include   56.356025   1.6471  -3.6076\n",
       "46   Topic10   16.913662            deep   58.548671   1.6330  -3.5836\n",
       "233  Topic10    6.629113         various   25.714992   1.5192  -4.5202\n",
       "92   Topic10    5.407130           image   21.097188   1.5134  -4.7240\n",
       "23   Topic10    6.476306         capture   26.598971   1.4620  -4.5435\n",
       "191  Topic10   11.116486        sequence   51.420883   1.3432  -4.0033\n",
       "32   Topic10    2.792354        computer   13.230184   1.3192  -5.3848\n",
       "81   Topic10    2.149238            form   10.617886   1.2773  -5.6466\n",
       "70   Topic10    4.972974         example   24.600350   1.2760  -4.8077\n",
       "76   Topic10    3.388168           field   16.812034   1.2730  -5.1914\n",
       "118  Topic10    7.311179         machine   36.548309   1.2655  -4.4223\n",
       "126  Topic10    4.964445        modeling   25.765150   1.2281  -4.8094\n",
       "122  Topic10    4.246190       mechanism   23.574439   1.1606  -4.9657\n",
       "10   Topic10   11.631644    architecture   65.937865   1.1398  -3.9580\n",
       "237  Topic10    2.571943          vision   17.353942   0.9656  -5.4670\n",
       "1    Topic10    7.158581         achieve   59.851537   0.7512  -4.4434\n",
       "125  Topic10   34.248020           model  557.390233   0.0851  -2.8781\n",
       "172  Topic10   46.400318             ref  969.648738  -0.1649  -2.5744\n",
       "12   Topic10    7.298626       attention   78.232562   0.5028  -4.4240\n",
       "150  Topic10    6.586291     performance   71.541100   0.4895  -4.5267\n",
       "212  Topic10    9.463791            task  311.382092  -0.6188  -4.1642\n",
       "106  Topic10    6.849889        language  328.821236  -0.9965  -4.4875\n",
       "222  Topic10    5.874133     transformer  183.237919  -0.5655  -4.6411\n",
       "215  Topic10    5.294309            text   84.290016   0.1071  -4.7451\n",
       "\n",
       "[447 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "0         3  0.157997     accuracy\n",
       "0         5  0.473991     accuracy\n",
       "0         8  0.315994     accuracy\n",
       "1         3  0.367576      achieve\n",
       "1         5  0.217204      achieve\n",
       "1         6  0.233912      achieve\n",
       "1         9  0.033416      achieve\n",
       "1        10  0.116956      achieve\n",
       "2         4  0.919376     addition\n",
       "3         1  0.093749        adopt\n",
       "3         5  0.656245        adopt\n",
       "3         7  0.187499        adopt\n",
       "4         4  0.674975      advance\n",
       "4         6  0.295301      advance\n",
       "5         3  0.572625     analysis\n",
       "5         5  0.286313     analysis\n",
       "5         7  0.114525     analysis\n",
       "6         3  0.233532       answer\n",
       "6         6  0.743058       answer\n",
       "7         3  0.185430  application\n",
       "7         4  0.247240  application\n",
       "7         9  0.494480  application\n",
       "8         3  0.155964        apply\n",
       "8         7  0.374314        apply\n",
       "8         9  0.374314        apply\n",
       "8        10  0.062386        apply\n",
       "9         1  0.179980     approach\n",
       "9         2  0.134985     approach\n",
       "9         3  0.104988     approach\n",
       "9         5  0.464948     approach\n",
       "...     ...       ...          ...\n",
       "233      10  0.272215      various\n",
       "234       2  0.977354          vec\n",
       "235       2  0.985599       vector\n",
       "236       4  0.340336      version\n",
       "236       5  0.255252      version\n",
       "236       6  0.170168      version\n",
       "236       7  0.170168      version\n",
       "237       4  0.288119       vision\n",
       "237       9  0.518614       vision\n",
       "237      10  0.172871       vision\n",
       "238       5  0.954160          way\n",
       "239       2  0.054136         wide\n",
       "239       3  0.703774         wide\n",
       "239       4  0.054136         wide\n",
       "239       8  0.162409         wide\n",
       "240       1  0.854738    wikipedia\n",
       "240       6  0.056983    wikipedia\n",
       "240      10  0.056983    wikipedia\n",
       "241       2  0.958812         word\n",
       "241       9  0.037235         word\n",
       "242       1  0.091944         work\n",
       "242       2  0.055166         work\n",
       "242       4  0.202277         work\n",
       "242       6  0.091944         work\n",
       "242       7  0.055166         work\n",
       "242       9  0.422942         work\n",
       "242      10  0.055166         work\n",
       "243       5  0.378570         year\n",
       "243       6  0.047321         year\n",
       "243       9  0.520534         year\n",
       "\n",
       "[819 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 6, 3, 5, 8, 9, 10, 7, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the LDA model with pyLDAvis?\n",
    "#The pyLDAvis offers the best visualization to view the topics-keywords distribution.\n",
    "\n",
    "#A good topic model will have non-overlapping, fairly big sized blobs for each topic. This seems to be the case here. So, we are good.\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>word</td>\n",
       "      <td>ref</td>\n",
       "      <td>embedding</td>\n",
       "      <td>use</td>\n",
       "      <td>representation</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence</td>\n",
       "      <td>vector</td>\n",
       "      <td>model</td>\n",
       "      <td>embed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>network</td>\n",
       "      <td>neural</td>\n",
       "      <td>ref</td>\n",
       "      <td>model</td>\n",
       "      <td>recently</td>\n",
       "      <td>propose</td>\n",
       "      <td>deep</td>\n",
       "      <td>include</td>\n",
       "      <td>cnn</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>model</td>\n",
       "      <td>ref</td>\n",
       "      <td>bert</td>\n",
       "      <td>language</td>\n",
       "      <td>elmo</td>\n",
       "      <td>use</td>\n",
       "      <td>pretraine</td>\n",
       "      <td>representation</td>\n",
       "      <td>large</td>\n",
       "      <td>recent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>ref</td>\n",
       "      <td>model</td>\n",
       "      <td>language</td>\n",
       "      <td>bert</td>\n",
       "      <td>train</td>\n",
       "      <td>transformer</td>\n",
       "      <td>representation</td>\n",
       "      <td>encoder</td>\n",
       "      <td>pre</td>\n",
       "      <td>bidirectional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>ref</td>\n",
       "      <td>bert</td>\n",
       "      <td>model</td>\n",
       "      <td>base</td>\n",
       "      <td>fine</td>\n",
       "      <td>method</td>\n",
       "      <td>tune</td>\n",
       "      <td>approach</td>\n",
       "      <td>good</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>language</td>\n",
       "      <td>task</td>\n",
       "      <td>ref</td>\n",
       "      <td>natural</td>\n",
       "      <td>processing</td>\n",
       "      <td>nlp</td>\n",
       "      <td>model</td>\n",
       "      <td>art</td>\n",
       "      <td>state</td>\n",
       "      <td>recently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>task</td>\n",
       "      <td>ref</td>\n",
       "      <td>representation</td>\n",
       "      <td>recent</td>\n",
       "      <td>learn</td>\n",
       "      <td>nlp</td>\n",
       "      <td>learning</td>\n",
       "      <td>transfer</td>\n",
       "      <td>sentence</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>ref</td>\n",
       "      <td>question</td>\n",
       "      <td>text</td>\n",
       "      <td>model</td>\n",
       "      <td>state</td>\n",
       "      <td>task</td>\n",
       "      <td>answer</td>\n",
       "      <td>art</td>\n",
       "      <td>bert</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>ref</td>\n",
       "      <td>layer</td>\n",
       "      <td>transformer</td>\n",
       "      <td>attention</td>\n",
       "      <td>model</td>\n",
       "      <td>bert</td>\n",
       "      <td>base</td>\n",
       "      <td>architecture</td>\n",
       "      <td>use</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>ref</td>\n",
       "      <td>token</td>\n",
       "      <td>sentence</td>\n",
       "      <td>datum</td>\n",
       "      <td>model</td>\n",
       "      <td>task</td>\n",
       "      <td>train</td>\n",
       "      <td>follow</td>\n",
       "      <td>training</td>\n",
       "      <td>predict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0    Word 1          Word 2     Word 3          Word 4  \\\n",
       "Topic 0      word       ref       embedding        use  representation   \n",
       "Topic 1   network    neural             ref      model        recently   \n",
       "Topic 2     model       ref            bert   language            elmo   \n",
       "Topic 3       ref     model        language       bert           train   \n",
       "Topic 4       ref      bert           model       base            fine   \n",
       "Topic 5  language      task             ref    natural      processing   \n",
       "Topic 6      task       ref  representation     recent           learn   \n",
       "Topic 7       ref  question            text      model           state   \n",
       "Topic 8       ref     layer     transformer  attention           model   \n",
       "Topic 9       ref     token        sentence      datum           model   \n",
       "\n",
       "              Word 5          Word 6          Word 7    Word 8         Word 9  \n",
       "Topic 0         bert        sentence          vector     model          embed  \n",
       "Topic 1      propose            deep         include       cnn        problem  \n",
       "Topic 2          use       pretraine  representation     large         recent  \n",
       "Topic 3  transformer  representation         encoder       pre  bidirectional  \n",
       "Topic 4       method            tune        approach      good          large  \n",
       "Topic 5          nlp           model             art     state       recently  \n",
       "Topic 6          nlp        learning        transfer  sentence           work  \n",
       "Topic 7         task          answer             art      bert            use  \n",
       "Topic 8         bert            base    architecture       use           self  \n",
       "Topic 9         task           train          follow  training        predict  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get top 10 keywords each topic\n",
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=10)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'ref', 'embedding', 'use', 'representation', 'bert', 'sentence', 'vector', 'model', 'embed']\n"
     ]
    }
   ],
   "source": [
    "#predict the topics for a new piece of text\n",
    "# Define function to predict topic for a given text document.\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def predict_topic(text, nlp=nlp):\n",
    "    global sent_to_words\n",
    "    global lemmatization\n",
    "\n",
    "    # Step 1: Clean with simple_preprocess\n",
    "    mytext_2 = list(sent_to_words(text))\n",
    "\n",
    "    # Step 2: Lemmatize\n",
    "    mytext_3 = lemmatization(mytext_2, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "    # Step 3: Vectorize transform\n",
    "    mytext_4 = vectorizer.transform(mytext_3)\n",
    "\n",
    "    # Step 4: LDA Transform\n",
    "    topic_probability_scores = best_lda_model.transform(mytext_4)\n",
    "    topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), :].values.tolist()\n",
    "    return topic, topic_probability_scores\n",
    "\n",
    "# Predict the topic\n",
    "mytext = [\"We implement a variant of the word-by-word attention model (Rockta ̈schel et al., 2016) using Tensorflow for this task, where we stack two addi- tional bidirectional RNNs upon the final sequence representation and incorporate character embed- ding for word-level representation. The pretrained GloVe (Pennington et al., 2014) word vectors are used to initialize word embedding. We also inte- grate the base BERT (Devlin et al., 2018) to im- prove contextual modeling\"]\n",
    "topic, prob_scores = predict_topic(text = mytext)\n",
    "print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = lda_output.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>Index</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT &lt;REF&gt; is one of a series of pre-trained n...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question &lt;REF&gt; Candidate Paragraph BERT : BERT...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecAtt + Doc Reader &lt;REF&gt; 31.4 BERT  50.2 BERT...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specifically, we use SQuAD 1.1 &lt;REF&gt;.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Specifically, we use SQuAD 1.1 &lt;REF&gt;.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In recent years, deep pre-training approaches ...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In recent years, transfer learning has achieve...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MKDM is implemented from BERT &lt;REF&gt;.</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In recent work, &lt;REF&gt; show that pretrained mod...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Inspired by the superiority of Transformer &lt;RE...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The autoregressive loss belongs to a large fam...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;REF&gt; study the self-attention of a Transforme...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;REF&gt; study the self-attention of a Transforme...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Recently, several pre-trained transformers suc...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model Architectures of BERT, GPT and ELMo Quot...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model Architectures of BERT, GPT and ELMo Quot...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Specifically, we focus on a new reading compre...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MTMSN utilizes a series of pre-trained Transfo...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;REF&gt; gives an overview of our model that aims...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>To obtain a universal representation for both ...</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Specifically, we first tokenize the question a...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Motivated by the desire to address the limitat...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The model is then trained with the objective t...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>We use EternalFeather project to train a CBow ...</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pre-trained sentence encoders such as ELMo &lt;RE...</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>We build on this latter line of work, focusing...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The BERT model &lt;REF&gt; has shown state-of-the-ar...</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>For our models, we used a TFIDF &lt;REF&gt;, a 2-lay...</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>This approach can also be applied in order to ...</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Similarly, &lt;REF&gt; present pretrained cross-ling...</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Hidden Layers for Representation: &lt;REF&gt; showed...</td>\n",
       "      <td>970</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Transfer learning has a long history in the fi...</td>\n",
       "      <td>971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>BERT &lt;REF&gt; represents the latest refinement in...</td>\n",
       "      <td>972</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>This model is similar to the large Transformer...</td>\n",
       "      <td>973</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Separation tokens may also be added to further...</td>\n",
       "      <td>974</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>We consider the task of document classificatio...</td>\n",
       "      <td>975</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Recent studies have shown that state-of-the-ar...</td>\n",
       "      <td>976</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>The rest of the architecture until the Span-wi...</td>\n",
       "      <td>977</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>The rest of the architecture until the Span-wi...</td>\n",
       "      <td>978</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Once we represent the inputs in this fashion, ...</td>\n",
       "      <td>979</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>We adopt the bidirectional pre-training encode...</td>\n",
       "      <td>980</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Meanwhile, neural network-based representation...</td>\n",
       "      <td>981</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>An evaluation exploring numerous embedding met...</td>\n",
       "      <td>982</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>BERT &lt;REF&gt; is also a contextual word represent...</td>\n",
       "      <td>983</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Second, modern open-domain QA systems are gene...</td>\n",
       "      <td>984</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>State of the art MRC models for Arabic based o...</td>\n",
       "      <td>985</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>As previously mentioned, the driver behind pro...</td>\n",
       "      <td>986</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Inspired by classical QA systems &lt;REF&gt;, we emp...</td>\n",
       "      <td>987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Our proposed reader is Bert &lt;REF&gt;, a pre-train...</td>\n",
       "      <td>988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Attention was introduced by &lt;REF&gt; for the enco...</td>\n",
       "      <td>989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>BERT &lt;REF&gt; and ELMo ) generate deep contextual...</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Recently, pre-trained language models were pro...</td>\n",
       "      <td>991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>As the size of the MedNLI dataset is limited t...</td>\n",
       "      <td>992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>We follow the data collection method used by N...</td>\n",
       "      <td>993</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Natural language inference is also a well stud...</td>\n",
       "      <td>994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Unsupervised: It is well known that unsupervis...</td>\n",
       "      <td>995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Our BERT L model fine-tunes the 24 layer 1024 ...</td>\n",
       "      <td>996</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Representation learning techniques at the word...</td>\n",
       "      <td>997</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>By leveraging pre-trained machine translation ...</td>\n",
       "      <td>998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>In 2018, the BERT (Bidirectional Encoder Repre...</td>\n",
       "      <td>999</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paragraph  Index  Topic\n",
       "0    BERT <REF> is one of a series of pre-trained n...      0      7\n",
       "1    Question <REF> Candidate Paragraph BERT : BERT...      1      1\n",
       "2    DecAtt + Doc Reader <REF> 31.4 BERT  50.2 BERT...      2      9\n",
       "3                Specifically, we use SQuAD 1.1 <REF>.      3      0\n",
       "4                Specifically, we use SQuAD 1.1 <REF>.      4      0\n",
       "5    In recent years, deep pre-training approaches ...      5      7\n",
       "6    In recent years, transfer learning has achieve...      6      7\n",
       "7                 MKDM is implemented from BERT <REF>.      7      4\n",
       "8    In recent work, <REF> show that pretrained mod...      8      4\n",
       "9    Inspired by the superiority of Transformer <RE...      9      4\n",
       "10   The autoregressive loss belongs to a large fam...     10      9\n",
       "11   <REF> study the self-attention of a Transforme...     11      4\n",
       "12   <REF> study the self-attention of a Transforme...     12      4\n",
       "13   Recently, several pre-trained transformers suc...     13      7\n",
       "14   Model Architectures of BERT, GPT and ELMo Quot...     14      0\n",
       "15   Model Architectures of BERT, GPT and ELMo Quot...     15      0\n",
       "16   Specifically, we focus on a new reading compre...     16      5\n",
       "17   MTMSN utilizes a series of pre-trained Transfo...     17      7\n",
       "18   <REF> gives an overview of our model that aims...     18      0\n",
       "19   To obtain a universal representation for both ...     19      7\n",
       "20   Specifically, we first tokenize the question a...     20      0\n",
       "21   Motivated by the desire to address the limitat...     21      0\n",
       "22   The model is then trained with the objective t...     22      7\n",
       "23   We use EternalFeather project to train a CBow ...     23      2\n",
       "24   Pre-trained sentence encoders such as ELMo <RE...     24      7\n",
       "25   We build on this latter line of work, focusing...     25      5\n",
       "26   The BERT model <REF> has shown state-of-the-ar...     26      7\n",
       "27   For our models, we used a TFIDF <REF>, a 2-lay...     27      4\n",
       "28   This approach can also be applied in order to ...     28      7\n",
       "29   Similarly, <REF> present pretrained cross-ling...     29      4\n",
       "..                                                 ...    ...    ...\n",
       "970  Hidden Layers for Representation: <REF> showed...    970      4\n",
       "971  Transfer learning has a long history in the fi...    971      0\n",
       "972  BERT <REF> represents the latest refinement in...    972      7\n",
       "973  This model is similar to the large Transformer...    973      7\n",
       "974  Separation tokens may also be added to further...    974      5\n",
       "975  We consider the task of document classificatio...    975      8\n",
       "976  Recent studies have shown that state-of-the-ar...    976      5\n",
       "977  The rest of the architecture until the Span-wi...    977      8\n",
       "978  The rest of the architecture until the Span-wi...    978      8\n",
       "979  Once we represent the inputs in this fashion, ...    979      5\n",
       "980  We adopt the bidirectional pre-training encode...    980      4\n",
       "981  Meanwhile, neural network-based representation...    981      5\n",
       "982  An evaluation exploring numerous embedding met...    982      2\n",
       "983  BERT <REF> is also a contextual word represent...    983      7\n",
       "984  Second, modern open-domain QA systems are gene...    984      5\n",
       "985  State of the art MRC models for Arabic based o...    985      5\n",
       "986  As previously mentioned, the driver behind pro...    986      7\n",
       "987  Inspired by classical QA systems <REF>, we emp...    987      4\n",
       "988  Our proposed reader is Bert <REF>, a pre-train...    988      7\n",
       "989  Attention was introduced by <REF> for the enco...    989      1\n",
       "990  BERT <REF> and ELMo ) generate deep contextual...    990      0\n",
       "991  Recently, pre-trained language models were pro...    991      7\n",
       "992  As the size of the MedNLI dataset is limited t...    992      4\n",
       "993  We follow the data collection method used by N...    993      5\n",
       "994  Natural language inference is also a well stud...    994      5\n",
       "995  Unsupervised: It is well known that unsupervis...    995      7\n",
       "996  Our BERT L model fine-tunes the 24 layer 1024 ...    996      7\n",
       "997  Representation learning techniques at the word...    997      2\n",
       "998  By leveraging pre-trained machine translation ...    998      2\n",
       "999  In 2018, the BERT (Bidirectional Encoder Repre...    999      7\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
